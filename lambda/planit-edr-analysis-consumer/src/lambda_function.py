import os
import json
import time
import logging
from datetime import datetime, timedelta, timezone

import boto3
from elasticsearch import Elasticsearch, ConnectionError, TransportError
from elastic_transport import ConnectionTimeout
from openai import OpenAI

# ---- ë¡œê¹… ì„¤ì • ----
logger = logging.getLogger()
logger.setLevel(os.getenv("LOG_LEVEL", "INFO").upper())

# ---- ê¸€ë¡œë²Œ í´ë¼ì´ì–¸íŠ¸ ----
ssm = boto3.client('ssm')
secrets_client = boto3.client('secretsmanager')
es_client = None
openai_client = None

def translate_fields_to_korean(openai_client, analysis_result):
    """
    analysis_result ì•ˆì˜ ì˜ì–´ í…ìŠ¤íŠ¸(analysis_summary, counter_evidence, reason)ë¥¼
    OpenAI APIë¡œ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” í•¨ìˆ˜
    """

    text_to_translate = f"""
    ì•„ë˜ ì„¸ ë¬¸ì¥ì„ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”.

    [analysis_summary]
    {analysis_result.get("analysis_summary", "")}

    [counter_evidence]
    {analysis_result.get("counter_evidence", "")}

    [reason]
    {analysis_result.get("reason", "")}

    ë²ˆì—­ ê²°ê³¼ëŠ” JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš” (analysis_summary_ko, counter_evidence_ko, reason_ko í•„ë“œ í¬í•¨).
    """

    try:
        response = openai_client.chat.completions.create(
            model="gpt-5",
            messages=[
                {"role": "system", "content": "You are a professional Korean translator specialized in cybersecurity."},
                {"role": "user", "content": text_to_translate}
            ],
            response_format={
                "type": "json_schema",
                "json_schema": {
                    "name": "kor_translation",
                    "strict": True,
                    "schema": {
                        "type": "object",
                        "properties": {
                            "analysis_summary_ko": {"type": "string"},
                            "counter_evidence_ko": {"type": "string"},
                            "reason_ko": {"type": "string"}
                        },
                        "required": ["analysis_summary_ko", "counter_evidence_ko", "reason_ko"],
                        "additionalProperties": False
                    }
                }
            }
        )

        return json.loads(response.choices[0].message.content)

    except Exception as e:
        logger.error(f"í•œêµ­ì–´ ë²ˆì—­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return {
            "analysis_summary_ko": "",
            "counter_evidence_ko": "",
            "reason_ko": ""
        }


# ---- í—¬í¼ í•¨ìˆ˜ ----
def get_parameter(ssm_client, name, with_decryption=True):
    try:
        response = ssm_client.get_parameter(Name=name, WithDecryption=with_decryption)
        return response['Parameter']['Value']
    except Exception as e:
        logger.error(f"SSMì—ì„œ '{name}' íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", exc_info=True)
        raise e

def initialize_clients():
    """ES ë° OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
    global es_client, openai_client
    if es_client is None or openai_client is None:
        logger.info("Initializing ES and OpenAI clients...")

        ES_HOST = get_parameter(ssm, '/planit/llm/es-host')
        ES_USER = get_parameter(ssm, '/planit/es-user/super')
        ES_PASSWORD = get_parameter(ssm, '/planit/es-password/super')

        # Elasticsearch ì•ˆì •í™” ì˜µì…˜
        es_client = Elasticsearch(
            hosts=[ES_HOST],
            basic_auth=(ES_USER, ES_PASSWORD),
            request_timeout=60,
            max_retries=5,
            retry_on_timeout=True
        )

        SECRET_NAME = get_parameter(ssm, '/planit/llm/secret-name')
        secret = json.loads(secrets_client.get_secret_value(SecretId=SECRET_NAME)['SecretString'])
        openai_client = OpenAI(api_key=secret['OPENAI_API_KEY'])
        logger.info("Clients initialized successfully.")

def fetch_document_with_retry(index, doc_id, retries=3, delay=2):
    """ES ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸° ì¬ì‹œë„"""
    for attempt in range(retries):
        try:
            return es_client.get(index=index, id=doc_id)
        except (ConnectionTimeout, ConnectionError, TransportError) as e:
            logger.warning(f"ES connection failed (attempt {attempt+1}/{retries}): {e}")
            time.sleep(delay)
        except Exception as e:
            logger.error(f"Unexpected error fetching ES document: {e}", exc_info=True)
            break
    return None

def clean_data_for_llm(data, placeholders=None):
    """
    ë°ì´í„°ë¥¼ LLMì— ì „ë‹¬í•˜ê¸° ì „ì— ì¬ê·€ì ìœ¼ë¡œ ì •ë¦¬
    -1, "-", "" ë“± "ì—†ìŒ"ì„ ì˜ë¯¸í•˜ëŠ” ê°’ë“¤ì„ None (JSON 'null')ìœ¼ë¡œ í†µì¼í•˜ì—¬ í† í° ì ˆì•½
    """
    if placeholders is None:
        placeholders = [-1, "-", ""]

    if isinstance(data, dict):
        return {k: clean_data_for_llm(v, placeholders) for k, v in data.items()}

    if isinstance(data, list):
        return [clean_data_for_llm(item, placeholders) for item in data]

    if data in placeholders:
        return None

    return data

def fetch_related_events(es_client, hostname, timestamp_str, main_event_id, index_pattern="edr-syslog-fixed*", window_seconds=60, size=20):
    """
    ì£¼ì–´ì§„ í˜¸ìŠ¤íŠ¸ì™€ ì‹œê°„ëŒ€ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì£¼ë³€ ë¡œê·¸(Context) ê²€ìƒ‰
    """
    if not hostname or not timestamp_str:
        logger.warning("Cannot fetch related events: HostName or @timestamp is missing from main event.")
        return []

    try:
        # 'Z' (UTC) ì²˜ë¦¬
        event_time = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
    except (ValueError, TypeError):
        logger.error(f"Invalid @timestamp format, cannot parse: {timestamp_str}")
        return []

    start_time = (event_time - timedelta(seconds=window_seconds)).isoformat()
    end_time = (event_time + timedelta(seconds=window_seconds)).isoformat()

    query_body = {
        "query": {
            "bool": {
                "must": [
                    {"match": {"edr.HostName": hostname}},
                    {"range": {"@timestamp": {"gte": start_time, "lte": end_time}}}
                ],
                "filter": [
                    {
                        "bool": {
                            "should": [
                                {"match": {"edr.EventType": "process"}},
                                {"match": {"edr.EventType": "network"}},
                                {"match": {"edr.EventType": "file"}},
                                {"match": {"edr.EventType": "registry"}}
                            ],
                            "minimum_should_match": 1
                        }
                    }
                ]
            }
        },
        "sort": [{"@timestamp": {"order": "asc"}}],
        "_source": [
            "@timestamp", "edr.HostName", "edr.ProcUserID",
            "edr.EventType", "edr.EventSubType",
            "edr.ProcName", "edr.ProcPath", "edr.CmdLine",
            "edr.ParentProcName", "edr.ParentProcPath", "edr.ParentProcCmdLine",
            "edr.Direction", "edr.RemoteIP", "edr.RemotePort", "edr.DNSName",
            "edr.FileName", "edr.FilePath", "edr.RegKeyPath", "edr.RegValueName"
        ],
        "size": size
    }
    
    logger.info(f"[DEBUG] Fetching related events for host: {hostname}, time: {timestamp_str}")

    try:
        response = es_client.search(index=index_pattern, body=query_body)
        return [hit['_source'] for hit in response['hits']['hits']]
    except Exception as e:
        logger.warning(f"Failed to fetch related events: {e}")
        return []

def call_openai_api(current_openai_client, doc_source, related_events=None):
    """OpenAI API í˜¸ì¶œ (Self-Evaluation & Context Aware & JSON Schema)"""

    if related_events is None:
        related_events = []

    detect_desc = doc_source.get("DetectDesc", {})

    # í•µì‹¬ í•„ë“œ ì„ ë³„
    main_event_context = {
        "NATIP": doc_source.get("NATIP"),
        "HostName": doc_source.get("HostName"),
        "IP": doc_source.get("IP"),
        "AuthName": doc_source.get("AuthName"),
        "Platform": doc_source.get("Platform"),
        "EventTime": doc_source.get("EventTime"), 
        "EventType": doc_source.get("EventType"),
        "EventSubType": doc_source.get("EventSubType"),
        "ProcName": doc_source.get("ProcName"), 
        "FileName": doc_source.get("FileName"),
        "CmdLine": doc_source.get("CmdLine"),   
        "ProcPath": doc_source.get("ProcPath"),
        "DetectTime": doc_source.get("DetectTime"),

        # Persistence ê´€ë ¨ í•„ë“œ
        "RegKeyPath": detect_desc.get("RegKeyPath") or doc_source.get("RegKeyPath"),
        "RegValueName": detect_desc.get("RegValueName") or doc_source.get("RegValueName"),
        "RegValue": detect_desc.get("RegValue") or doc_source.get("RegData"),

        "RuleName": doc_source.get("RuleName"),
        "RuleID": doc_source.get("RuleID"),
        "DetectSubType": doc_source.get("DetectSubType"),
        "ThreatID": doc_source.get("ThreatID"),
        "Tactic": doc_source.get("Tactic"),
        "TacticID": doc_source.get("TacticID"),
        "Technique": doc_source.get("Technique"),
        "TechniqueID": doc_source.get("TechniqueID"),
        "ResponseInfo": doc_source.get("ResponseInfo"),
        "SuspiciousInfo": doc_source.get("SuspiciousInfo"),
        "SuspiciousInfo2": doc_source.get("SuspiciousInfo2")
    }

    # ë°ì´í„° ì •ì œ (null ì²˜ë¦¬)
    cleaned_main_event = clean_data_for_llm(main_event_context)
    cleaned_related_events = clean_data_for_llm(related_events)

    context_data = {
        "main_event": cleaned_main_event,
        "related_events_60sec_window": cleaned_related_events
    }

    prompt = f"""
    You are a Tier 3 Threat Hunter specialized in **Contextual Anomaly Detection**.

    **Your Core Objective:**
    Distinguish between **True Threats (APT, Malware)** and **Benign Administrative Activities (Software deployment, Debugging, Remote management)**.
    - Missing a real threat is bad (False Negative).
    - But flooding the SOC with false alarms on admin activity is ALSO bad (False Positive).
    - **Balance is key.**

    **ğŸš¨ CRITICAL OVERRIDE RULE - SIMULATIONS & DRILLS:**
    - If you see indicators of **Atomic Red Team**, **Red Canary**, **Breach and Attack Simulation (BAS)**, or command lines explicitly mentioning "Test", "Simulation", "victim" (e.g., `curl ... atomic-red-team ...`):
        1. **Result:** MUST be **1 (Malicious)**. (We need to prove detection).
        2. **Confidence:** MUST be **Low (60-65)**.
        3. **Reason:** State clearly "Detected Security Simulation / Drill Activity".
    - **Why?** This allows the SOC to see the alert (Result 1) but prioritize it lower than real APT attacks (Confidence 90+).

    **Analysis Process (Chain of Thought):**
    1.  **Analyze Context:** Look at the `main_event` within the `related_events_60sec_window`.
    2.  **Devil's Advocate (Crucial):** Before deciding, force yourself to find reasons why your initial gut feeling might be WRONG.
        - If it looks malicious: Ask "Could this be a clumsy admin or a weird scheduled task?"
        - If it looks normal: Ask "Could this be a stealthy attacker blending in (Living off the Land)?"
    3.  **Verdict:** Only decide after weighing both sides.
    4.  **Scoring:** Assign confidence strictly based on the rubric below.

    **Critical Instructions for Classification:**
    1.  **Analyze Context:** Analyze the `main_event` in the *context* of the `related_events_60sec_window`.
    2.  **'Normal' vs 'Malicious':** A single admin tool (like powershell.exe) in `main_event` might look suspicious alone. But if the `related_events` show normal preceding activity (like logging in, opening admin tools), it is likely 'normal'.
    3.  **'Malicious' Indicators:** Look for suspicious *sequences*, like Office apps (winword.exe, excel.exe) launching powershell.exe, or downloads followed by execution from temp folders.

    ---
    **Analyze the following data package:**
    (The `related_events_60sec_window` shows other logs from the same host +-60 seconds around the `main_event`)
    {json.dumps(context_data, ensure_ascii=False, indent=2)}

    ---
    Classify the `main_event` (NOT the related events) as 'malicious' or 'normal' and explain your reasoning *based on the full context*.

    ---
    Classify the `main_event` using the following codes:
    - **0**: Normal (Safe, Benign)
    - **1**: Malicious (Threat, Suspicious)

    ---
    **Your Task:**
    1. Determine if the event is Normal (0) or Malicious (1).
    2. **Self-Evaluate your confidence score (0-100)** based on the evidence strength.

    **Confidence Scoring Rubric (Strict enforcement):**
    - **95-100:** Absolute Certainty. Matches a known APT signature, hash, or exact MITRE attack pattern with NO benign explanation.
    - **80-94:** High Confidence. Strong anomaly (e.g., encoded PowerShell, credential dumping attempt) but theoretically possible by an admin.
    - **60-79:** Suspicious. Weird behavior, but lacks context or could be a false positive.
    - **0-59:** Low Confidence. Insufficient data, generic logs, or highly likely to be noise.
    """

    try:
        response = current_openai_client.chat.completions.create(
            model="gpt-5", # ì‚¬ìš©í•˜ì‹œëŠ” ëª¨ë¸ëª… ìœ ì§€
            messages=[
                {"role": "system", "content": "You are a top-tier cybersecurity analyst."},
                {"role": "user", "content": prompt}
            ],
            # Structured Outputs (Schema) ì ìš©
            response_format={
                "type": "json_schema",
                "json_schema": {
                    "name": "threat_classification",
                    "strict": True,
                    "schema": {
                        "type": "object",
                        "properties": {
                            "analysis_summary": {"type": "string", "description": "Brief summary of what happened."},
                            "counter_evidence": {"type": "string", "description": "Reasons why the OPPOSITE verdict might be true."},
                            "result": {"type": "integer", "enum": [0, 1], "description": "0 for Normal, 1 for Malicious"},
                            "reason": {"type": "string", "description": "Reasoning for the classification"},
                            "confidence": {"type": "integer", "minimum": 0, "maximum": 100, "description": "Confidence score"}
                        },
                        "required": ["analysis_summary", "counter_evidence", "result", "reason", "confidence"],
                        "additionalProperties": False
                    }
                }
            }
        )

        analysis_content = response.choices[0].message.content
        parsed_json = json.loads(analysis_content)
        confidence_score = float(parsed_json.get("confidence", 0))
        
        return parsed_json, confidence_score

    except Exception as e:
        logger.error("OpenAI API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", exc_info=True)
        return None, 0.0


# ---- Lambda í•¸ë“¤ëŸ¬ (Step Function Map Stateìš©) ----
def lambda_handler(event, context):
    """
    Step Function Map ìƒíƒœì—ì„œ ì „ë‹¬ëœ ë‹¨ì¼ 'event' ì²˜ë¦¬
    Payload ì˜ˆì‹œ: {'UniqueID': 'id-123', 'SourceIndex': 'src-idx', 'DestIndex': 'dest-idx'}
    """
    
    payload = event
    unique_id = payload.get('UniqueID')
    source_index = payload.get('SourceIndex')
    dest_index = payload.get('DestIndex')

    logger.info(f"Processing event from Step Function for UniqueID: {unique_id}")

    try:
        initialize_clients()

        if not unique_id or not source_index or not dest_index:
            logger.error(f"Message missing UniqueID, SourceIndex, or DestIndex.", extra={"payload": payload})
            raise ValueError("Message missing UniqueID, SourceIndex, or DestIndex.")

        # 1. ES ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
        doc = fetch_document_with_retry(source_index, unique_id)
        if not doc:
            raise Exception(f"Failed to fetch document '{unique_id}' from ES")
        doc_source = doc['_source']

        # 2. ì£¼ë³€ ì´ë²¤íŠ¸(Context) ê°€ì ¸ì˜¤ê¸° (ì—…ë°ì´íŠ¸ëœ ë¶€ë¶„)
        event_hostname = doc_source.get("HostName")
        event_timestamp = doc_source.get("@timestamp") # íƒ€ì„ìŠ¤íƒ¬í”„ í•„ë“œëª… í™•ì¸ í•„ìš”
        
        related_events = fetch_related_events(
            es_client=es_client,
            hostname=event_hostname,
            timestamp_str=event_timestamp,
            main_event_id=unique_id,
            index_pattern="edr-syslog-fixed*", # í•„ìš”ì‹œ íŒŒë¼ë¯¸í„°í™” ê°€ëŠ¥
            window_seconds=60,
            size=20
        )

        # 3. OpenAI ë¶„ì„ (Context í¬í•¨ í˜¸ì¶œ)
        analysis_result, confidence_score = call_openai_api(openai_client, doc_source, related_events)

        
        if not analysis_result:
            raise Exception(f"AI analysis result was None for UniqueID '{unique_id}'")

        # 4. ê²°ê³¼ íŒŒì‹± ë° í¬ë§·íŒ…
        ai_prediction_code = analysis_result.get("result") # 0 or 1
        ai_prediction_str = "malicious" if ai_prediction_code == 1 else "normal"

        # # ì •í™•ë„ ê²€ì¦ ë¡œì§ (ë°ì´í„°ì— ì •ë‹µì…‹ì´ ìˆì„ ê²½ìš°ì—ë§Œ ë™ì‘)
        # threat_label = doc_source.get("threat_label", {})
        # ground_truth = threat_label.get("verdict") if isinstance(threat_label, dict) else None
        
        # is_correct = None
        # if ground_truth is not None:
        #     is_correct = (ai_prediction_str == str(ground_truth).lower())
        #     logger.info(f"Accuracy Check [ID: {unique_id}]: AI={ai_prediction_str}, GT={ground_truth}, Correct={is_correct}")

        # í•œêµ­ì–´ ë²ˆì—­
        kor_translated = translate_fields_to_korean(openai_client, analysis_result)

        # 5. ê²°ê³¼ Doc êµ¬ì„±
        # doc_source['ai_analysis'] = {
        #     "result": ai_prediction_str,
        #     "result_code": ai_prediction_code,
        #     "reason": analysis_result.get("reason"),
        #     "analysis_summary": analysis_result.get("analysis_summary"),
        #     "counter_evidence": analysis_result.get("counter_evidence"),
        #     "confidence": confidence_score,
        #     "analyzed_at": datetime.now().isoformat(),
        #     "context_events_count": len(related_events)
        # }

        doc_source['ai_analysis'] = {
            # í•œêµ­ì–´ ë²ˆì—­ ê²°ê³¼
            "analysis_summary": kor_translated.get("analysis_summary_ko"),
            "counter_evidence": kor_translated.get("counter_evidence_ko"),
            "reason": kor_translated.get("reason_ko"),

            # ë¶„ë¥˜ ì •ë³´
            "result": ai_prediction_str,
            "result_code": ai_prediction_code,
            "confidence": confidence_score,

            "analyzed_at": datetime.now().isoformat(),
            "context_events_count": len(related_events)
        }

        # --- ì˜ì–´ ì›ë³¸ ì €ì¥ (ì˜ì–´ ì „ìš© í•„ë“œ) ---
        doc_source['ai_analysis_eng'] = {
            "analysis_summary_eng": analysis_result.get("analysis_summary"),
            "counter_evidence_eng": analysis_result.get("counter_evidence"),
            "reason_eng": analysis_result.get("reason")
        }

        # 6. ES ì €ì¥ (ë‹¨ì¼ Index API ì‚¬ìš©)
        # Step Functionì´ ê° ì•„ì´í…œì„ ê°œë³„ ì‹¤í–‰í•˜ë¯€ë¡œ Bulkê°€ ì•„ë‹Œ Index API ì‚¬ìš©
        es_client.index(
            index=dest_index,
            id=unique_id,
            document=doc_source
        )

        logger.info(f"Successfully processed and indexed UniqueID: {unique_id} to {dest_index}")
        
        # SFN Map ìƒíƒœ ê²°ê³¼ ë°˜í™˜
        return {"status": "success", "unique_id": unique_id, "prediction": ai_prediction_str}

    except Exception as e:
        logger.error(f"Failed to process message UniqueID '{unique_id}': {e}", exc_info=True)
        raise e