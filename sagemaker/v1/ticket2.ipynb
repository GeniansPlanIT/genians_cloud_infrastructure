{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5f3aa99-e0e7-4f38-8596-df45d8d1cd33",
   "metadata": {},
   "source": [
    "# 티켓을 묶어보자! (임베딩 저장 ver)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6634ad81-215b-454b-83a4-e2ff82f96d28",
   "metadata": {},
   "source": [
    "## Library Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b27016c-add3-49ae-9c32-f6e0b0a81b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26a53627-3c2f-4a14-8553-2e00e052946a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting elasticsearch<8.0.0,>=7.17.0\n",
      "  Downloading elasticsearch-7.17.12-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting urllib3<2,>=1.21.1 (from elasticsearch<8.0.0,>=7.17.0)\n",
      "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from elasticsearch<8.0.0,>=7.17.0) (2025.8.3)\n",
      "Downloading elasticsearch-7.17.12-py2.py3-none-any.whl (385 kB)\n",
      "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "Installing collected packages: urllib3, elasticsearch\n",
      "\u001b[2K  Attempting uninstall: urllib3\n",
      "\u001b[2K    Found existing installation: urllib3 2.5.0\n",
      "\u001b[2K    Uninstalling urllib3-2.5.0:\n",
      "\u001b[2K      Successfully uninstalled urllib3-2.5.0\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [elasticsearch]0m [elasticsearch]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.3 which is incompatible.\n",
      "sphinx 8.1.3 requires docutils<0.22,>=0.20, but you have docutils 0.19 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed elasticsearch-7.17.12 urllib3-1.26.20\n"
     ]
    }
   ],
   "source": [
    "# Elasticsearch 7.x 서버와 호환되는 7.17.x 버전 라이브러리를 설치합니다.\n",
    "!pip install \"elasticsearch<8.0.0,>=7.17.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f32d294f-4ef9-4287-abbd-8eb151e73a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numexpr in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.7.3)\n",
      "Collecting numexpr\n",
      "  Downloading numexpr-2.14.1.tar.gz (119 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from numexpr) (1.26.4)\n",
      "Building wheels for collected packages: numexpr\n",
      "  Building wheel for numexpr (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for numexpr: filename=numexpr-2.14.1-cp310-cp310-linux_x86_64.whl size=163286 sha256=cb084c859af016b72ac24784141857eb1e41a9c51c091130238eddb234bde4df\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/c4/16/c7/6252b16a24e3bb6f20a4e95105f016c31fffa5f38f64b46d5c\n",
      "Successfully built numexpr\n",
      "Installing collected packages: numexpr\n",
      "  Attempting uninstall: numexpr\n",
      "    Found existing installation: numexpr 2.7.3\n",
      "    Uninstalling numexpr-2.7.3:\n",
      "      Successfully uninstalled numexpr-2.7.3\n",
      "Successfully installed numexpr-2.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f6c44f9-8ece-4852-800a-22e19470abc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (2025.9.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch)\n",
      "  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m  \u001b[33m0:00:15\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m212.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m155.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m  \u001b[33m0:00:14\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m176.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.6.0-cp310-cp310-manylinux1_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m126.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
      "\u001b[2K  Attempting uninstall: sympy━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/18\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Found existing installation: sympy 1.14.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/18\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Uninstalling sympy-1.14.0:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/18\u001b[0m [sympy]parselt-cu12]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.14.0━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/18\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/18\u001b[0m [torchaudio]8\u001b[0m [torchaudio]]ver-cu12]2]\n",
      "\u001b[1A\u001b[2KSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.6.0 torchaudio-2.6.0 torchvision-0.21.0 triton-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c87bf1-c9c0-418a-8f1c-a9c0566eca5f",
   "metadata": {},
   "source": [
    "## Library Import & AWS Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d17e39d4-7ee5-47f8-8961-51b9032c55c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch, helpers as es_helpers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "927a286d-501b-446b-8591-8ef4bafe595f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSM Parameter Store에서 접속 정보를 성공적으로 가져왔습니다.\n"
     ]
    }
   ],
   "source": [
    "ssm_client = boto3.client('ssm')\n",
    "\n",
    "try:\n",
    "    # Lambda 코드에서 사용된 파라미터 경로를 그대로 사용합니다.\n",
    "    ES_HOST = ssm_client.get_parameter(Name='/planit/llm/es-host')['Parameter']['Value']\n",
    "    ES_USER = ssm_client.get_parameter(Name='/planit/es-user')['Parameter']['Value']\n",
    "    ES_PASSWORD = ssm_client.get_parameter(Name='/planit/es-password', WithDecryption=True)['Parameter']['Value']\n",
    "    \n",
    "    print(\"SSM Parameter Store에서 접속 정보를 성공적으로 가져왔습니다.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"SSM Parameter Store에서 정보를 가져오는 데 실패했습니다.\")\n",
    "    print(\"IAM 역할에 'ssm:GetParameter' 권한이 있는지 확인하세요.\")\n",
    "    print(f\"오류: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6e4739-b480-4d43-92bc-9cac242cf9e1",
   "metadata": {},
   "source": [
    "## Create an Elasticsearch Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b98f924f-ca53-410e-a8e0-877a0a2adea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch에 성공적으로 연결되었습니다.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    es_client = Elasticsearch(\n",
    "        ES_HOST,\n",
    "        http_auth=(ES_USER, ES_PASSWORD),\n",
    "        request_timeout=100\n",
    "    )\n",
    "\n",
    "    # 연결 테스트: True가 반환되면 성공\n",
    "    if es_client.ping():\n",
    "        print(\"Elasticsearch에 성공적으로 연결되었습니다.\")\n",
    "    else:\n",
    "        print(\"Elasticsearch 연결에 실패했습니다. 호스트 주소나 인증 정보를 확인하세요.\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"ES_HOST, ES_USER, ES_PASSWORD 변수가 설정되지 않았습니다. 이전 셀을 먼저 실행하세요.\")\n",
    "except Exception as e:\n",
    "    print(f\"Elasticsearch 연결 중 오류가 발생했습니다: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3864ca74-3c22-437d-9b2c-f7b52268cfda",
   "metadata": {},
   "source": [
    "## Retrieve Data from an Elasticsearch Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee72cf64-7c83-40a6-bd29-251ef745be3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'['planit-edr-ai-training-2025.10.03_15', 'planit-edr-ai-training-2025.10.16_16']' 인덱스에서 지정된 하위 필드까지 포함하여 조회를 시작합니다...\n"
     ]
    }
   ],
   "source": [
    "INDEX_PATTERN = [\n",
    "    \"planit-edr-ai-training-2025.10.03_15\",\n",
    "    \"planit-edr-ai-training-2025.10.16_16\"\n",
    "]\n",
    "\n",
    "# 1. 가져올 필드 목록을 점 표기법을 사용하여 상세하게 정의합니다.\n",
    "fields_to_include = [\n",
    "    # --- 기본 최상위 필드 ---\n",
    "    \"CmdLine\", \"DetectSubType\", \"DetectTime\",\n",
    "    \"EventSubType\", \"EventTime\", \"EventType\", \"FileName\", \"FileType\", \"HostName\",\n",
    "    \"IP\", \"IsKnown\", \"Platform\", \"ProcName\", \"ProcPath\",\n",
    "    \"RuleName\", \"SHA256\", \"Tactic\", \"TacticID\", \"Technique\", \"TechniqueID\",\n",
    "    \"threat_label.verdict\", \"threat_label.scenario\", \"threat_label.case_id\",\n",
    "\n",
    "    # --- SuspiciousInfo 하위 필드 ---\n",
    "    \"SuspliciousInfo\",\n",
    "\n",
    "    # --- ResponseInfo 하위 필드---\n",
    "    \"ResponseInfo\"\n",
    "]\n",
    "\n",
    "# 2. 기존 쿼리에 _source 파라미터를 추가합니다.\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"match_all\": {}\n",
    "    },\n",
    "    \"_source\": fields_to_include\n",
    "}\n",
    "\n",
    "print(f\"'{INDEX_PATTERN}' 인덱스에서 지정된 하위 필드까지 포함하여 조회를 시작합니다...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c649892-9fe7-4da8-a810-d5fa66c3e7fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 58개의 문서를 가져왔습니다.\n",
      "\n",
      "생성된 데이터프레임의 컬럼 목록:\n",
      "Index(['DetectSubType', 'IsKnown', 'Platform', 'EventType', 'ProcName',\n",
      "       'FileName', 'IP', 'CmdLine', 'DetectTime', 'EventSubType', 'SHA256',\n",
      "       'FileType', 'EventTime', 'ProcPath', 'HostName', 'RuleName',\n",
      "       'ResponseInfo_detect_terminateprocess', 'threat_label_scenario',\n",
      "       'threat_label_verdict', 'threat_label_case_id', 'Tactic', 'TacticID',\n",
      "       'TechniqueID', 'Technique', 'ResponseInfo'],\n",
      "      dtype='object')\n",
      "\n",
      "데이터프레임 샘플:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DetectSubType</th>\n",
       "      <th>IsKnown</th>\n",
       "      <th>Platform</th>\n",
       "      <th>EventType</th>\n",
       "      <th>ProcName</th>\n",
       "      <th>FileName</th>\n",
       "      <th>IP</th>\n",
       "      <th>CmdLine</th>\n",
       "      <th>DetectTime</th>\n",
       "      <th>EventSubType</th>\n",
       "      <th>...</th>\n",
       "      <th>RuleName</th>\n",
       "      <th>ResponseInfo_detect_terminateprocess</th>\n",
       "      <th>threat_label_scenario</th>\n",
       "      <th>threat_label_verdict</th>\n",
       "      <th>threat_label_case_id</th>\n",
       "      <th>Tactic</th>\n",
       "      <th>TacticID</th>\n",
       "      <th>TechniqueID</th>\n",
       "      <th>Technique</th>\n",
       "      <th>ResponseInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ransomware</td>\n",
       "      <td>False</td>\n",
       "      <td>Microsoft Windows 10 x64</td>\n",
       "      <td>file</td>\n",
       "      <td>520bd9ed608c668810971dbd51184c6a29819674280b01...</td>\n",
       "      <td>520bd9ed608c668810971dbd51184c6a29819674280b01...</td>\n",
       "      <td>192.168.105.135</td>\n",
       "      <td>\"C:\\Users\\SeohyeonKang\\Desktop\\Downloads (1)\\랜...</td>\n",
       "      <td>1759473364306</td>\n",
       "      <td>FileMove</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'Description': '자식 프로세스', 'SystemService': F...</td>\n",
       "      <td>Ransomware</td>\n",
       "      <td>malicious</td>\n",
       "      <td>INCIDENT-20251003-026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exploit</td>\n",
       "      <td>False</td>\n",
       "      <td>Microsoft Windows 10 x64</td>\n",
       "      <td>network</td>\n",
       "      <td>powershell.exe</td>\n",
       "      <td>powershell.exe</td>\n",
       "      <td>192.168.105.135</td>\n",
       "      <td>powershell.exe -ExecutionPolicy Bypass -C \"[Sy...</td>\n",
       "      <td>1760085055908</td>\n",
       "      <td>NetworkConnect</td>\n",
       "      <td>...</td>\n",
       "      <td>스크립트를 이용한 네트워크 접속</td>\n",
       "      <td>[{'Description': '의심 행위를 수행한 프로세스', 'SystemSer...</td>\n",
       "      <td>Ingress Tool Transfer - PSTools download &amp; unpack</td>\n",
       "      <td>malicious</td>\n",
       "      <td>INCIDENT-20251010-45</td>\n",
       "      <td>[Execution, Defense Evasion]</td>\n",
       "      <td>[TA0002, TA0005]</td>\n",
       "      <td>[T1064]</td>\n",
       "      <td>[Scripting]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ransomware</td>\n",
       "      <td>False</td>\n",
       "      <td>Microsoft Windows 10 x64</td>\n",
       "      <td>file</td>\n",
       "      <td>243dff06fc80a049f4fb37292f8b8def0fce29768f345c...</td>\n",
       "      <td>243dff06fc80a049f4fb37292f8b8def0fce29768f345c...</td>\n",
       "      <td>192.168.105.135</td>\n",
       "      <td>\"C:\\Users\\SeohyeonKang\\Desktop\\Downloads (1)\\랜...</td>\n",
       "      <td>1759472610576</td>\n",
       "      <td>FileMove</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'Description': '자식 프로세스', 'SystemService': F...</td>\n",
       "      <td>Ransomware</td>\n",
       "      <td>malicious</td>\n",
       "      <td>INCIDENT-20251003-025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exploit</td>\n",
       "      <td>False</td>\n",
       "      <td>Microsoft Windows 10 x64</td>\n",
       "      <td>process</td>\n",
       "      <td>splunkd.exe</td>\n",
       "      <td>powershell.exe</td>\n",
       "      <td>192.168.105.135</td>\n",
       "      <td>\"C:\\Users\\Public\\splunkd.exe\" -server http://1...</td>\n",
       "      <td>1760085055068</td>\n",
       "      <td>ProcessStart</td>\n",
       "      <td>...</td>\n",
       "      <td>의심스러운 파워쉘 실행</td>\n",
       "      <td>[{'Description': '의심 행위를 수행한 프로세스', 'SystemSer...</td>\n",
       "      <td>Ingress Tool Transfer - PSTools download &amp; unpack</td>\n",
       "      <td>malicious</td>\n",
       "      <td>INCIDENT-20251010-45</td>\n",
       "      <td>[Execution]</td>\n",
       "      <td>[TA0002]</td>\n",
       "      <td>[T1086]</td>\n",
       "      <td>[PowerShell]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anomaly</td>\n",
       "      <td>False</td>\n",
       "      <td>Microsoft Windows 10 x64</td>\n",
       "      <td>file</td>\n",
       "      <td>cmd.exe</td>\n",
       "      <td>ping.exe</td>\n",
       "      <td>192.168.105.135</td>\n",
       "      <td>\"C:\\Windows\\System32\\cmd.exe\"  /C ping 127.0.0...</td>\n",
       "      <td>1759471610178</td>\n",
       "      <td>FileDelete</td>\n",
       "      <td>...</td>\n",
       "      <td>자가 삭제</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ransomware</td>\n",
       "      <td>malicious</td>\n",
       "      <td>INCIDENT-20251003-024</td>\n",
       "      <td>[Defense Evasion]</td>\n",
       "      <td>[TA0005]</td>\n",
       "      <td>[T1107]</td>\n",
       "      <td>[File Deletion]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  DetectSubType  IsKnown                  Platform EventType  \\\n",
       "0    Ransomware    False  Microsoft Windows 10 x64      file   \n",
       "1       Exploit    False  Microsoft Windows 10 x64   network   \n",
       "2    Ransomware    False  Microsoft Windows 10 x64      file   \n",
       "3       Exploit    False  Microsoft Windows 10 x64   process   \n",
       "4       Anomaly    False  Microsoft Windows 10 x64      file   \n",
       "\n",
       "                                            ProcName  \\\n",
       "0  520bd9ed608c668810971dbd51184c6a29819674280b01...   \n",
       "1                                     powershell.exe   \n",
       "2  243dff06fc80a049f4fb37292f8b8def0fce29768f345c...   \n",
       "3                                        splunkd.exe   \n",
       "4                                            cmd.exe   \n",
       "\n",
       "                                            FileName               IP  \\\n",
       "0  520bd9ed608c668810971dbd51184c6a29819674280b01...  192.168.105.135   \n",
       "1                                     powershell.exe  192.168.105.135   \n",
       "2  243dff06fc80a049f4fb37292f8b8def0fce29768f345c...  192.168.105.135   \n",
       "3                                     powershell.exe  192.168.105.135   \n",
       "4                                           ping.exe  192.168.105.135   \n",
       "\n",
       "                                             CmdLine     DetectTime  \\\n",
       "0  \"C:\\Users\\SeohyeonKang\\Desktop\\Downloads (1)\\랜...  1759473364306   \n",
       "1  powershell.exe -ExecutionPolicy Bypass -C \"[Sy...  1760085055908   \n",
       "2  \"C:\\Users\\SeohyeonKang\\Desktop\\Downloads (1)\\랜...  1759472610576   \n",
       "3  \"C:\\Users\\Public\\splunkd.exe\" -server http://1...  1760085055068   \n",
       "4  \"C:\\Windows\\System32\\cmd.exe\"  /C ping 127.0.0...  1759471610178   \n",
       "\n",
       "     EventSubType  ...           RuleName  \\\n",
       "0        FileMove  ...               None   \n",
       "1  NetworkConnect  ...  스크립트를 이용한 네트워크 접속   \n",
       "2        FileMove  ...               None   \n",
       "3    ProcessStart  ...       의심스러운 파워쉘 실행   \n",
       "4      FileDelete  ...              자가 삭제   \n",
       "\n",
       "                ResponseInfo_detect_terminateprocess  \\\n",
       "0  [{'Description': '자식 프로세스', 'SystemService': F...   \n",
       "1  [{'Description': '의심 행위를 수행한 프로세스', 'SystemSer...   \n",
       "2  [{'Description': '자식 프로세스', 'SystemService': F...   \n",
       "3  [{'Description': '의심 행위를 수행한 프로세스', 'SystemSer...   \n",
       "4                                                NaN   \n",
       "\n",
       "                               threat_label_scenario threat_label_verdict  \\\n",
       "0                                         Ransomware            malicious   \n",
       "1  Ingress Tool Transfer - PSTools download & unpack            malicious   \n",
       "2                                         Ransomware            malicious   \n",
       "3  Ingress Tool Transfer - PSTools download & unpack            malicious   \n",
       "4                                         Ransomware            malicious   \n",
       "\n",
       "    threat_label_case_id                        Tactic          TacticID  \\\n",
       "0  INCIDENT-20251003-026                           NaN               NaN   \n",
       "1   INCIDENT-20251010-45  [Execution, Defense Evasion]  [TA0002, TA0005]   \n",
       "2  INCIDENT-20251003-025                           NaN               NaN   \n",
       "3   INCIDENT-20251010-45                   [Execution]          [TA0002]   \n",
       "4  INCIDENT-20251003-024             [Defense Evasion]          [TA0005]   \n",
       "\n",
       "  TechniqueID        Technique ResponseInfo  \n",
       "0         NaN              NaN          NaN  \n",
       "1     [T1064]      [Scripting]          NaN  \n",
       "2         NaN              NaN          NaN  \n",
       "3     [T1086]     [PowerShell]          NaN  \n",
       "4     [T1107]  [File Deletion]          NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# 모든 문서 가져오기\n",
    "doc_list = [doc['_source'] for doc in es_helpers.scan(es_client, index=INDEX_PATTERN, query=query)]\n",
    "print(f\"총 {len(doc_list)}개의 문서를 가져왔습니다.\")\n",
    "\n",
    "# json_normalize를 사용하여 데이터프레임 생성(점(.)을 언더스코어(_)로 바꿔줌)\n",
    "df = pd.json_normalize(doc_list, sep='_')\n",
    "\n",
    "# 결과 확인\n",
    "print(\"\\n생성된 데이터프레임의 컬럼 목록:\")\n",
    "print(df.columns)\n",
    "\n",
    "# 데이터프레임 상위 5개 샘플 출력\n",
    "print(\"\\n데이터프레임 샘플:\")\n",
    "print(display(df.head()))\n",
    "\n",
    "# 파일로 저장\n",
    "# raw_file_name = 'raw_data.csv'\n",
    "# df.to_csv(file_name, index=False, encoding='utf-8-sig')\n",
    "\n",
    "raw_file_name = 'raw_data.json'\n",
    "df.to_json(raw_file_name, orient='records', force_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c3c00dad-1759-4351-af01-765bcd2a660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- threat_label.scenario 별 개수 ---\n",
      "threat_label_scenario\n",
      "Ransomware                                                                10\n",
      "Execution - Remote Access/Support Tool                                     6\n",
      "Masquerading - File Extension Masquerading                                 4\n",
      "Ingress Tool Transfer - Curl download of remote DLL                        3\n",
      "Account Manipulation - Create new Windows admin user                       2\n",
      "Ingress Tool Transfer - PowerShell file download                           2\n",
      "Create or Modify System Process - Modify Fax service to run PowerShell     2\n",
      "Account Manipulation - Create new Windows admin user via PowerShell        2\n",
      "Execution - Remote Access/Remote Tools                                     2\n",
      "Indicator Removal - Stop terminal from logging history                     2\n",
      "Masquerading - LSASS process masquerade                                    2\n",
      "Ingress Tool Transfer - PSTools download & unpack                          2\n",
      "Impair Defenses - Disable or Modify Security Tools                         2\n",
      "Indicator Removal - Prevent PowerShell history logging                     2\n",
      "Hide Artifacts - Create Hidden File with Attrib                            2\n",
      "Ingress Tool Transfer - Windows Defender MpCmdRun download                 1\n",
      "Web Shell Written to Disk                                                  1\n",
      "Server Software Component - Terminal Services DLL                          1\n",
      "Signed Binary Proxy Execution - Rundll32                                   1\n",
      "System Discovery - Read Volume Boot Sector via DOS Device Path             1\n",
      "Hide Artifacts - Hidden Window                                             1\n",
      "Indicator Removal - FSUtil / USN Journal                                   1\n",
      "Hide Artifacts - Create Hidden User                                        1\n",
      "Masquerading - Malicious process masquerading as LSM.exe                   1\n",
      "Command and Scripting Interpreter - PowerShell (Move & Triage)             1\n",
      "Indicator Removal - Clear Windows Event Logs                               1\n",
      "Impair Defenses - Disable Microsoft Defender Firewall                      1\n",
      "Defense Evasion - Change PowerShell Execution Policy                       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 'threat_label_scenario' 컬럼의 값별 개수를 셉니다.\n",
    "scenario_counts = df['threat_label_scenario'].value_counts()\n",
    "\n",
    "# 결과를 출력합니다.\n",
    "print(\"--- threat_label.scenario 별 개수 ---\")\n",
    "print(scenario_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e61abe8f-0306-4e51-8d83-82d55179ce28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- threat_label.case_id 별 개수 ---\n",
      "threat_label_case_id\n",
      "INCIDENT-20251003-024    4\n",
      "INCIDENT-20251001-010    4\n",
      "INCIDENT-20251010-41     3\n",
      "INCIDENT-20251010-45     2\n",
      "INCIDENT-20251001-001    2\n",
      "INCIDENT-20251001-003    2\n",
      "INCIDENT-20251002-019    2\n",
      "INCIDENT-20251010-44     2\n",
      "INCIDENT-20251002-022    2\n",
      "INCIDENT-20251010-35     2\n",
      "INCIDENT-20251010-37     2\n",
      "INCIDENT-20251003-023    2\n",
      "INCIDENT-20251002-016    2\n",
      "INCIDENT-20251001-008    2\n",
      "INCIDENT-20251001-005    2\n",
      "INCIDENT-20251001-004    2\n",
      "INCIDENT-20251002-021    2\n",
      "INCIDENT-20251003-026    1\n",
      "INCIDENT-20251003-025    1\n",
      "INCIDENT-20251010-39     1\n",
      "INCIDENT-20251002-017    1\n",
      "INCIDENT-20251002-018    1\n",
      "INCIDENT-20251010-36     1\n",
      "INCIDENT-20251002-020    1\n",
      "INCIDENT-20251010-38     1\n",
      "INCIDENT-20251010-42     1\n",
      "INCIDENT-20251010-40     1\n",
      "INCIDENT-20251001-015    1\n",
      "INCIDENT-20251001-012    1\n",
      "INCIDENT-20251001-011    1\n",
      "INCIDENT-20251001-014    1\n",
      "INCIDENT-20251001-013    1\n",
      "INCIDENT-20251001-002    1\n",
      "INCIDENT-20251001-006    1\n",
      "INCIDENT-20251001-007    1\n",
      "INCIDENT-20251001-009    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 'threat_label_case_id' 컬럼의 값별 개수를 셉니다.\n",
    "case_id_counts = df['threat_label_case_id'].value_counts()\n",
    "\n",
    "# 결과를 출력합니다.\n",
    "print(\"\\n--- threat_label.case_id 별 개수 ---\")\n",
    "print(case_id_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e341c558-ded3-4b3f-a333-0d0e75b1300e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Case ID 별 시나리오 및 개수 ---\n",
      " threat_label_case_id                                                  threat_label_scenario  count\n",
      "INCIDENT-20251003-024                                                             Ransomware      4\n",
      "INCIDENT-20251001-010                             Masquerading - File Extension Masquerading      4\n",
      " INCIDENT-20251010-41                    Ingress Tool Transfer - Curl download of remote DLL      3\n",
      "INCIDENT-20251001-001                                                             Ransomware      2\n",
      "INCIDENT-20251003-023                                                             Ransomware      2\n",
      "INCIDENT-20251001-004                     Impair Defenses - Disable or Modify Security Tools      2\n",
      "INCIDENT-20251001-003                 Indicator Removal - Stop terminal from logging history      2\n",
      "INCIDENT-20251001-005                 Indicator Removal - Prevent PowerShell history logging      2\n",
      "INCIDENT-20251002-019 Create or Modify System Process - Modify Fax service to run PowerShell      2\n",
      "INCIDENT-20251002-022    Account Manipulation - Create new Windows admin user via PowerShell      2\n",
      "INCIDENT-20251001-008                        Hide Artifacts - Create Hidden File with Attrib      2\n",
      "INCIDENT-20251002-016                                Masquerading - LSASS process masquerade      2\n",
      "INCIDENT-20251002-021                   Account Manipulation - Create new Windows admin user      2\n",
      " INCIDENT-20251010-37                                 Execution - Remote Access/Support Tool      2\n",
      " INCIDENT-20251010-44                       Ingress Tool Transfer - PowerShell file download      2\n",
      " INCIDENT-20251010-35                                 Execution - Remote Access/Remote Tools      2\n",
      " INCIDENT-20251010-45                      Ingress Tool Transfer - PSTools download & unpack      2\n",
      "INCIDENT-20251001-002         Command and Scripting Interpreter - PowerShell (Move & Triage)      1\n",
      "INCIDENT-20251001-007                  Impair Defenses - Disable Microsoft Defender Firewall      1\n",
      "INCIDENT-20251001-009                   Defense Evasion - Change PowerShell Execution Policy      1\n",
      "INCIDENT-20251002-020                      Server Software Component - Terminal Services DLL      1\n",
      "INCIDENT-20251002-018                                              Web Shell Written to Disk      1\n",
      "INCIDENT-20251002-017         System Discovery - Read Volume Boot Sector via DOS Device Path      1\n",
      "INCIDENT-20251001-015                               Signed Binary Proxy Execution - Rundll32      1\n",
      "INCIDENT-20251001-013                                    Hide Artifacts - Create Hidden User      1\n",
      "INCIDENT-20251001-014               Masquerading - Malicious process masquerading as LSM.exe      1\n",
      "INCIDENT-20251001-011                                         Hide Artifacts - Hidden Window      1\n",
      "INCIDENT-20251001-012                               Indicator Removal - FSUtil / USN Journal      1\n",
      "INCIDENT-20251001-006                           Indicator Removal - Clear Windows Event Logs      1\n",
      " INCIDENT-20251010-36                                 Execution - Remote Access/Support Tool      1\n",
      "INCIDENT-20251003-025                                                             Ransomware      1\n",
      "INCIDENT-20251003-026                                                             Ransomware      1\n",
      " INCIDENT-20251010-40                                 Execution - Remote Access/Support Tool      1\n",
      " INCIDENT-20251010-39                                 Execution - Remote Access/Support Tool      1\n",
      " INCIDENT-20251010-38                                 Execution - Remote Access/Support Tool      1\n",
      " INCIDENT-20251010-42             Ingress Tool Transfer - Windows Defender MpCmdRun download      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 'threat_label_case_id'와 'threat_label_scenario'로 그룹화하고 각 그룹의 개수를 셉니다.\n",
    "# .reset_index(name='count')는 결과를 보기 좋은 데이터프레임으로 만들어줍니다.\n",
    "case_scenario_counts = df.groupby(['threat_label_case_id', 'threat_label_scenario']).size().reset_index(name='count')\n",
    "\n",
    "# 'count' 컬럼을 기준으로 내림차순 정렬하여 개수가 많은 순으로 보여줍니다.\n",
    "case_scenario_counts = case_scenario_counts.sort_values(by='count', ascending=False)\n",
    "\n",
    "# 결과를 출력합니다.\n",
    "# .to_string(index=False)를 사용하면 데이터프레임의 인덱스 번호 없이 깔끔하게 출력됩니다.\n",
    "print(\"--- Case ID 별 시나리오 및 개수 ---\")\n",
    "print(case_scenario_counts.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd4528f1-3d7f-41c4-868e-ea2c8463b5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 지정된 시나리오의 Case ID 별 개수 ---\n",
      " threat_label_case_id                      threat_label_scenario  count\n",
      "INCIDENT-20251001-010 Masquerading - File Extension Masquerading      4\n",
      "INCIDENT-20251003-024                                 Ransomware      4\n",
      "INCIDENT-20251001-001                                 Ransomware      2\n",
      "INCIDENT-20251003-023                                 Ransomware      2\n",
      " INCIDENT-20251010-37     Execution - Remote Access/Support Tool      2\n",
      "INCIDENT-20251003-026                                 Ransomware      1\n",
      "INCIDENT-20251003-025                                 Ransomware      1\n",
      " INCIDENT-20251010-36     Execution - Remote Access/Support Tool      1\n",
      " INCIDENT-20251010-38     Execution - Remote Access/Support Tool      1\n",
      " INCIDENT-20251010-39     Execution - Remote Access/Support Tool      1\n",
      " INCIDENT-20251010-40     Execution - Remote Access/Support Tool      1\n"
     ]
    }
   ],
   "source": [
    "# 1. case_id와 scenario를 기준으로 그룹화하여 개수를 셉니다.\n",
    "case_scenario_counts = df.groupby(['threat_label_case_id', 'threat_label_scenario']).size().reset_index(name='count')\n",
    "\n",
    "\n",
    "# 2. 필터링할 시나리오 목록을 만듭니다.\n",
    "scenarios_to_show = [\n",
    "    'Ransomware',\n",
    "    'Execution - Remote Access/Support Tool',\n",
    "    'Masquerading - File Extension Masquerading'\n",
    "]\n",
    "\n",
    "# 3. isin() 메서드를 사용해 원하는 시나리오만 포함된 행을 선택합니다.\n",
    "filtered_counts = case_scenario_counts[case_scenario_counts['threat_label_scenario'].isin(scenarios_to_show)]\n",
    "\n",
    "\n",
    "# 4. 필터링된 결과를 'count' 기준으로 내림차순 정렬합니다.\n",
    "sorted_counts = filtered_counts.sort_values(by='count', ascending=False)\n",
    "\n",
    "\n",
    "# 5. 최종 결과를 인덱스 없이 깔끔하게 출력합니다.\n",
    "print(\"--- 지정된 시나리오의 Case ID 별 개수 ---\")\n",
    "print(sorted_counts.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b67db6a-8b34-41af-af1f-87b8c64452ba",
   "metadata": {},
   "source": [
    "## 기본 feature 추출\n",
    "- 범주형 feature: EventType, EventSubType, RuleName, DetectSubType\n",
    "- 텍스트 feature: CmdLine, ProcPath, FileName\n",
    "- 시간 feature: EventTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43d6edfa-705a-415e-a170-525f13a5b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d1db947-b06a-4c36-bcf5-6bfa5d2afcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering을 위한 data frame 복사\n",
    "feature_df = df.copy()\n",
    "\n",
    "# 각 feature 처리 단계에서 생성된 결과를 저장할 리스트\n",
    "# feature_list = [feature_df]\n",
    "feature_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42f78030-5d51-4afa-98d7-de901f346541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EventType] unique values:\n",
      "['file' 'network' 'process' 'registry']\n",
      "\n",
      "[EventSubType] unique values:\n",
      "['FileMove' 'NetworkConnect' 'ProcessStart' 'FileDelete' 'RegSetValue'\n",
      " 'Amsi' 'FileCreate' 'HttpDownload' 'FileCopy' 'RunScript']\n",
      "\n",
      "[DetectSubType] unique values:\n",
      "['Ransomware' 'Exploit' 'Anomaly' 'Autorun' 'Misc' 'Fake']\n",
      "\n",
      "[RuleName] unique values:\n",
      "[None '스크립트를 이용한 네트워크 접속' '의심스러운 파워쉘 실행' '자가 삭제' '의심스러운 자동실행 등록'\n",
      " '파워쉘 Fileless 커맨드' 'Dropper 의심 프로세스' 'Windows 유틸리티를 이용한 다운로드'\n",
      " '의심스러운 스크립트 실행' '사용자 계정 등록 시도' '의심스러운 윈도우 서비스'\n",
      " 'Web Shell Written to Disk'\n",
      " 'Read volume boot sector via DOS device path (PowerShell)'\n",
      " 'Windows 관련 파일로 위장하는 가짜 Windows 파일' 'Rundll32을 이용한 위협적인 실행' '이벤트로그 삭제'\n",
      " 'Hidden Window' '2중 확장자를 이용한 속임수 파일 실행'\n",
      " 'Create Windows Hidden File with Attrib' '방화벽 우회 시도'\n",
      " 'Grant Full Access to folder for Everyone - Ryuk Ransomware Style'\n",
      " 'Disable Windows Defender All' 'Prevent Powershell History Logging'\n",
      " 'Avoid logs']\n",
      "\n",
      "[RuleId] column not found in DataFrame\n"
     ]
    }
   ],
   "source": [
    "columns_to_check = ['EventType', 'EventSubType', 'DetectSubType', 'RuleName', 'RuleId']\n",
    "\n",
    "for col in columns_to_check:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n[{col}] unique values:\")\n",
    "        print(df[col].unique())\n",
    "    else:\n",
    "        print(f\"\\n[{col}] column not found in DataFrame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65b9d23-8700-4e8c-8c49-571b3c14878c",
   "metadata": {},
   "source": [
    "### Temporal Features\n",
    "- EventTime 기준으로 Time Difference 계산해 새로운 컬럼 만들기\n",
    "- 공격의 연속성 파악\n",
    "- 공격의 인과 관계 순서를 파악 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23cf3666-8d7a-4c82-bc18-ebf8ff5b6b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 1. 시간 피처 처리 시작 ###\n",
      "-> 완료: 시간 차이(time_diff_sec) 피처 생성.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"### 1. 시간 피처 처리 시작 ###\")\n",
    "\n",
    "# HostName 또는 EventTime 컬럼이 없는 경우를 대비한 예외 처리\n",
    "if 'HostName' in feature_df.columns and 'EventTime' in feature_df.columns:\n",
    "    feature_df['EventTime_dt'] = pd.to_datetime(feature_df['EventTime'], unit='ms')\n",
    "    # 데이터를 정렬하고 인덱스를 리셋하여 순서를 고정\n",
    "    feature_df = feature_df.sort_values(by=['HostName', 'EventTime_dt']).reset_index(drop=True)\n",
    "    \n",
    "    time_diff = feature_df.groupby('HostName')['EventTime_dt'].diff().dt.total_seconds().fillna(0)\n",
    "    feature_df['time_diff_sec'] = np.maximum(time_diff, 0)\n",
    "    \n",
    "    # 생성된 피처를 feature_list에 추가\n",
    "    feature_list.append(feature_df[['time_diff_sec']])\n",
    "    print(\"-> 완료: 시간 차이(time_diff_sec) 피처 생성.\\n\")\n",
    "else:\n",
    "    print(\"-> 경고: 'HostName' 또는 'EventTime' 컬럼이 없어 시간 피처를 생성하지 않았습니다.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65c3da7-0a5c-443c-8eed-3098ef91f575",
   "metadata": {},
   "source": [
    "### Categorical Features\n",
    "EventType, EventSubType, RuleName, DetectSubType -> 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8263b644-f709-4674-985e-2cb9dea863e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 2. 범주형 피처 처리 시작 ###\n",
      "원-핫 인코딩으로 44개의 피처 생성 완료.\n",
      "생성된 피처 예시 (상위 5개):\n",
      "   EventType_file  EventType_network  EventType_process  EventType_registry  \\\n",
      "0            True              False              False               False   \n",
      "1            True              False              False               False   \n",
      "2            True              False              False               False   \n",
      "3           False              False               True               False   \n",
      "4           False              False               True               False   \n",
      "\n",
      "   EventSubType_Amsi  EventSubType_FileCopy  EventSubType_FileCreate  \\\n",
      "0               True                  False                    False   \n",
      "1               True                  False                    False   \n",
      "2               True                  False                    False   \n",
      "3              False                  False                    False   \n",
      "4              False                  False                    False   \n",
      "\n",
      "   EventSubType_FileDelete  EventSubType_FileMove  EventSubType_HttpDownload  \\\n",
      "0                    False                  False                      False   \n",
      "1                    False                  False                      False   \n",
      "2                    False                  False                      False   \n",
      "3                    False                  False                      False   \n",
      "4                    False                  False                      False   \n",
      "\n",
      "   ...  RuleName_방화벽 우회 시도  RuleName_사용자 계정 등록 시도  RuleName_스크립트를 이용한 네트워크 접속  \\\n",
      "0  ...               False                  False                       False   \n",
      "1  ...               False                  False                       False   \n",
      "2  ...               False                  False                       False   \n",
      "3  ...               False                  False                       False   \n",
      "4  ...               False                  False                       False   \n",
      "\n",
      "   RuleName_의심스러운 스크립트 실행  RuleName_의심스러운 윈도우 서비스  RuleName_의심스러운 자동실행 등록  \\\n",
      "0                   False                   False                   False   \n",
      "1                   False                   False                   False   \n",
      "2                   False                   False                   False   \n",
      "3                   False                   False                   False   \n",
      "4                   False                   False                   False   \n",
      "\n",
      "   RuleName_의심스러운 파워쉘 실행  RuleName_이벤트로그 삭제  RuleName_자가 삭제  \\\n",
      "0                  False              False           False   \n",
      "1                  False              False           False   \n",
      "2                  False              False           False   \n",
      "3                  False              False           False   \n",
      "4                  False              False           False   \n",
      "\n",
      "   RuleName_파워쉘 Fileless 커맨드  \n",
      "0                      False  \n",
      "1                      False  \n",
      "2                      False  \n",
      "3                      False  \n",
      "4                      False  \n",
      "\n",
      "[5 rows x 44 columns]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"### 2. 범주형 피처 처리 시작 ###\")\n",
    "\n",
    "# 처리할 범주형 컬럼 목록\n",
    "categorical_cols = ['EventType', 'EventSubType', 'DetectSubType', 'RuleName']\n",
    "\n",
    "# 결측값(NaN)을 'Unknown' 문자열로 대체\n",
    "# for col in categorical_cols:\n",
    "#     feature_df[col] = feature_df[col].fillna('Unknown')\n",
    "for col in categorical_cols:\n",
    "    if col in feature_df.columns:\n",
    "        feature_df[col] = feature_df[col].fillna('Unknown')\n",
    "\n",
    "# Pandas의 get_dummies를 사용한 원-핫 인코딩\n",
    "# 각 카테고리 값을 새로운 컬럼으로 만들고, 해당하면 1 아니면 0으로 채움\n",
    "categorical_features = pd.get_dummies(feature_df[categorical_cols], prefix=categorical_cols)\n",
    "feature_list.append(categorical_features)\n",
    "\n",
    "print(f\"원-핫 인코딩으로 {categorical_features.shape[1]}개의 피처 생성 완료.\")\n",
    "print(\"생성된 피처 예시 (상위 5개):\")\n",
    "print(categorical_features.head())\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c056e475-1d78-4178-9669-b3e45de77b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 피처가 'categorical_features.csv' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 전체 컬럼 목록을 csv 파일로 저장\n",
    "output_file = 'categorical_features.csv'\n",
    "categorical_features.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"전체 피처가 '{output_file}' 파일에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccb46cf-2022-46f9-bc0e-564242a62a8f",
   "metadata": {},
   "source": [
    "### Text Features\n",
    "`만들어진 cmdline_features_df에서 랜섬이라는 단어가 들어간 column과 특정 이름이 들어간 column drop해야 할 듯`\n",
    "- CmdLine -> TF-IDF Vectorizer\n",
    "- ProcName, FileName은 어떻게 하지?\n",
    "- TfidVectorizer: 단순히 단어의 빈도수만 세는 것이 아니라, 모든 문서에서 공통적으로 많이 나타나는 단어에는 낮은 가중치를, 특정 문서에만 집중적으로 나타나는 단어에는 높은 가중치 부여"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c332aab7-c3e9-4284-b505-629c018b206c",
   "metadata": {},
   "source": [
    "#### CmdLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7147c5c2-e9d1-4b0b-954f-434f15637374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 3. 텍스트 피처 처리 시작 ###\n",
      "-> 완료: TF-IDF로 100개 피처 생성.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"### 3. 텍스트 피처 처리 시작 ###\")\n",
    "\n",
    "if 'CmdLine' in feature_df.columns:\n",
    "    feature_df['CmdLine'] = feature_df['CmdLine'].fillna('')\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=100, ngram_range=(1, 2))\n",
    "    cmdline_features_matrix = tfidf_vectorizer.fit_transform(feature_df['CmdLine'])\n",
    "    cmdline_features_df = pd.DataFrame(\n",
    "        cmdline_features_matrix.toarray(),\n",
    "        columns=[f\"cmd_{name}\" for name in tfidf_vectorizer.get_feature_names_out()]\n",
    "    )\n",
    "    feature_list.append(cmdline_features_df)\n",
    "    print(f\"-> 완료: TF-IDF로 {cmdline_features_df.shape[1]}개 피처 생성.\\n\")\n",
    "else:\n",
    "    print(\"-> 경고: 'CmdLine' 컬럼이 없어 텍스트 피처를 생성하지 않았습니다.\\n\")\n",
    "\n",
    "# # TF-IDF를 적용할 텍스트 컬럼 (CmdLine)\n",
    "# # 결측값(NaN)을 빈 문자열 ''로 대체\n",
    "# feature_df['CmdLine'] = feature_df['CmdLine'].fillna('')\n",
    "\n",
    "# # TF-IDF Vectorizer 초기화\n",
    "# # max_features: 가장 빈번하게 나타나는 단어 N개만 피처로 사용 (차원 축소)\n",
    "# # ngrams_range: 단어 묶음의 범위 (예: (1, 2)는 단어 1개와 2개를 모두 고려)\n",
    "# tfidf_vectorizer = TfidfVectorizer(max_features=100, ngram_range=(1, 2))\n",
    "\n",
    "# # CmdLine에 대해 TF-IDF 학습 및 변환 수행\n",
    "# cmdline_features_matrix = tfidf_vectorizer.fit_transform(feature_df['CmdLine'])\n",
    "\n",
    "# # 결과를 데이터프레임으로 변환\n",
    "# cmdline_features_df = pd.DataFrame(\n",
    "#     cmdline_features_matrix.toarray(),\n",
    "#     columns=[f\"cmd_{name}\" for name in tfidf_vectorizer.get_feature_names_out()]\n",
    "# )\n",
    "# feature_list.append(cmdline_features_df)\n",
    "\n",
    "# print(f\"TF-IDF로 {cmdline_features_df.shape[1]}개의 피처 생성 완료.\")\n",
    "# print(\"생성된 피처 예시 (상위 5개):\")\n",
    "# print(cmdline_features_df.head())\n",
    "# print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c17fdbd9-3ba1-4848-9c18-573026125996",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 피처가 'cmdline_features_df.csv' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 전체 컬럼 목록을 csv 파일로 저장\n",
    "output_file = 'cmdline_features_df.csv'\n",
    "cmdline_features_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"전체 피처가 '{output_file}' 파일에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9399f413-e522-40a7-88b4-9f85be6b8259",
   "metadata": {},
   "source": [
    "### Path Features\n",
    "- ProcPath -> Tokenizer + LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c891ec-98a3-4b6c-a4d8-ee0730d072ab",
   "metadata": {},
   "source": [
    "#### ProcPath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039e0116-ebdc-4c1b-bda8-957dd3159d71",
   "metadata": {},
   "source": [
    "기본 설정 및 경로 토큰화 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b9cf3b5f-20f2-470c-a354-3993d8061ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 4. 경로(ProcPath, FileName) 피처 처리 시작 ###\n"
     ]
    }
   ],
   "source": [
    "print(\"### 4. 경로(ProcPath, FileName) 피처 처리 시작 ###\")\n",
    "\n",
    "def tokenize_path(path):\n",
    "    \"\"\"\n",
    "    경로 문자열을 입력받아 토큰 리스트로 변환하는 함수.\n",
    "    - None이나 NaN 값은 빈 리스트로 처리.\n",
    "    - 모든 문자를 소문자로 변환.\n",
    "    - '\\', '/', '.' 를 기준으로 분리.\n",
    "    \"\"\"\n",
    "    if not isinstance(path, str):\n",
    "        return []\n",
    "    # 정규표현식을 사용하여 여러 구분자로 분리\n",
    "    tokens = re.split(r'[\\\\/.]', path.lower())\n",
    "    # 빈 문자열 제거 (예: '/usr/bin' -> ['', 'usr', 'bin'])\n",
    "    return [token for token in tokens if token]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841d8012-c781-490e-9e24-321cbd3625bd",
   "metadata": {},
   "source": [
    "[삭제] 단어 사전 구축\n",
    "? seohyeonkang 괜찮냐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "96ec474e-7d19-4632-a8a2-f409f4a45c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모든 경로에서 나온 토큰들을 하나의 리스트로 통합\n",
    "# all_tokens = [token for tokens_list in df['ProcPath_tokens'] for token in tokens_list]\n",
    "\n",
    "# # 토큰 빈도수 계산\n",
    "# token_counts = Counter(all_tokens)\n",
    "\n",
    "# # 가장 빈번하게 등장하는 토큰 1000개를 단어 사전에 추가 (예시)\n",
    "# # 실제 데이터에서는 데이터의 크기에 맞게 조절합니다.\n",
    "# vocab = [token for token, count in token_counts.most_common(1000)]\n",
    "\n",
    "# # 특수 토큰 추가\n",
    "# # <pad>: 문장 길이를 맞추기 위한 패딩 토큰\n",
    "# # <unk>: 단어 사전에 없는 단어를 위한 UNKNOWN 토큰\n",
    "# special_tokens = ['<pad>', '<unk>']\n",
    "# vocab = special_tokens + vocab\n",
    "\n",
    "# # 각 토큰에 정수 인덱스를 부여하는 딕셔너리 생성\n",
    "# word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "# idx_to_word = {idx: word for idx, word in enumerate(vocab)}\n",
    "\n",
    "# vocab_size = len(vocab)\n",
    "\n",
    "# print(f\"### 단어 사전 구축 완료 ###\")\n",
    "# print(f\"단어 사전 크기: {vocab_size}\")\n",
    "# print(f\"일부 샘플: {list(word_to_idx.items())[:10]}\")\n",
    "# print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879b0e50-5182-40e8-ad79-3db955fdb9a8",
   "metadata": {},
   "source": [
    "PyTorch Sequential Model 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44a3349d-53ee-4ad0-838e-dd6e05cd4f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathEmbedder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(PathEmbedder, self).__init__()\n",
    "        \n",
    "        # 1. 임베딩 레이어: 정수 인덱스를 밀집 벡터로 변환\n",
    "        # padding_idx=0: <pad> 토큰은 학습 과정에서 무시하도록 설정\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        # 2. LSTM 레이어: 임베딩된 벡터 시퀀스를 입력받아 문맥을 학습\n",
    "        # batch_first=True: 입력 텐서의 차원을 (batch_size, sequence_length, ...) 순으로 받음\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # paths_tensor: (batch_size, max_sequence_length)\n",
    "        \n",
    "        # 1. 임베딩\n",
    "        embedded = self.embedding(x)\n",
    "        # embedded: (batch_size, max_sequence_length, embedding_dim)\n",
    "        \n",
    "        # 2. LSTM\n",
    "        # LSTM의 마지막 hidden state가 경로 전체의 문맥 정보를 압축한 결과물\n",
    "        _, (hidden, _) = self.lstm(embedded)\n",
    "        # hidden: (1, batch_size, hidden_dim)\n",
    "        \n",
    "        # 최종 출력 벡터의 차원을 (batch_size, hidden_dim)으로 조정\n",
    "        final_embedding = hidden.squeeze(0)\n",
    "        \n",
    "        return final_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afa9be0-ee40-49cb-832b-2d18b5b88aee",
   "metadata": {},
   "source": [
    "임베딩 추출 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ddbefd8-3029-45e5-81f7-274ce7549340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_to_tensor(paths, word_to_idx):\n",
    "    \"\"\"\n",
    "    경로 문자열 리스트를 토큰화, 인덱싱, 패딩하여 텐서로 변환하는 함수.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. 토큰화 및 정수 인덱싱\n",
    "    # 사전에 없으면 <unk> 토큰의 인덱스로, 있으면 해당 토큰의 인덱스로 변환\n",
    "    indexed_paths = [[word_to_idx.get(token, word_to_idx['<unk>']) for token in tokenize_path(p)] for p in paths]\n",
    "\n",
    "    # 2. 패딩 (길이 맞추기)\n",
    "    max_len = max(len(p) for p in indexed_paths) if indexed_paths else 0\n",
    "    padded_paths = [p + [word_to_idx['<pad>']] * (max_len - len(p)) for p in indexed_paths]\n",
    "    \n",
    "    # 3. PyTorch 텐서로 변환\n",
    "    return torch.LongTensor(padded_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae27dab-186a-42c7-8218-178f569308cc",
   "metadata": {},
   "source": [
    "전체 경로 토큰에 대한 단어 사전 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6cea64fb-39b1-4f1c-aeaa-6264c115a7e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> 완료: ProcPath에 대한 64차원 임베딩 피처 생성.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ProcPath 컬럼이 있는지 먼저 확인\n",
    "if 'ProcPath' in feature_df.columns:\n",
    "    # 단어 사전(Vocabulary)을 ProcPath 기준으로 구축\n",
    "    all_path_tokens = [token for path in feature_df['ProcPath'].dropna() for token in tokenize_path(path)]\n",
    "    vocab = ['<pad>', '<unk>'] + [token for token, _ in Counter(all_path_tokens).most_common(2000)]\n",
    "    word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "    vocab_size = len(word_to_idx)\n",
    "\n",
    "    # 모델 인스턴스 생성\n",
    "    EMBEDDING_DIM = 32  # 각 토큰을 표현할 벡터의 차원\n",
    "    HIDDEN_DIM = 64    # 경로 전체를 표현할 최종 임베딩 벡터의 차원\n",
    "    path_embedder_model = PathEmbedder(vocab_size, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "    path_embedder_model.eval()\n",
    "\n",
    "    # ProcPath에 대한 임베딩 추출\n",
    "    with torch.no_grad():\n",
    "        procpath_tensor = paths_to_tensor(feature_df['ProcPath'].tolist(), word_to_idx)\n",
    "        procpath_embeddings = path_embedder_model(procpath_tensor).numpy()\n",
    "        procpath_df = pd.DataFrame(procpath_embeddings, columns=[f'pp_emb_{i}' for i in range(HIDDEN_DIM)])\n",
    "        feature_list.append(procpath_df)\n",
    "        print(f\"-> 완료: ProcPath에 대한 {HIDDEN_DIM}차원 임베딩 피처 생성.\\n\")\n",
    "else:\n",
    "    print(\"-> 경고: 'ProcPath' 컬럼이 없어 경로 피처를 생성하지 않았습니다.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e81c4cc-3639-4668-950b-62a5bf57199f",
   "metadata": {},
   "source": [
    "### MITRE ATT&CK Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "70d3d240-095e-40f8-8d47-cbce17aaa6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "195f615e-bf95-4e95-97af-24b062a87041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 5. MITRE ATT&CK 정보('Tactic', 'TacticID', 'Technique', 'TechniqueID') 피처 처리 시작 ###\n",
      "-> 완료: ATT&CK 관련 피처 19개 생성.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"### 5. MITRE ATT&CK 정보('Tactic', 'TacticID', 'Technique', 'TechniqueID') 피처 처리 시작 ###\")\n",
    "\n",
    "# Tactic, Technique의 'ID' 컬럼만 선택하여 처리\n",
    "attack_cols_by_id = ['TacticID', 'TechniqueID'] \n",
    "all_attack_features = []\n",
    "\n",
    "attack_mlbs = {}\n",
    "for col in attack_cols_by_id:\n",
    "    if col in feature_df.columns:\n",
    "        # 결측치(NaN)를 빈 리스트로 변환\n",
    "        series = feature_df[col].apply(lambda d: d if isinstance(d, list) else [])\n",
    "        \n",
    "        # MultiLabelBinarizer 초기화 및 학습/변환\n",
    "        mlb = MultiLabelBinarizer()\n",
    "        encoded_matrix = mlb.fit_transform(series)\n",
    "        attack_mlbs[col] = mlb\n",
    "        \n",
    "        # 인코딩된 결과가 있을 경우에만 데이터프레임으로 만들고 리스트에 추가\n",
    "        if encoded_matrix.shape[1] > 0:\n",
    "            # 컬럼 이름을 'TacticID_TA0001'과 같이 생성\n",
    "            attack_df = pd.DataFrame(encoded_matrix, columns=[f\"{col}_{cls}\" for cls in mlb.classes_])\n",
    "            all_attack_features.append(attack_df)\n",
    "        else:\n",
    "            print(f\"   - '{col}' 컬럼에 유효한 값이 없어 피처를 생성하지 않습니다.\")\n",
    "\n",
    "if all_attack_features:\n",
    "    # 생성된 모든 ATT&CK 피처 데이터프레임을 하나로 합침\n",
    "    attack_features_combined = pd.concat(all_attack_features, axis=1)\n",
    "    feature_list.append(attack_features_combined)\n",
    "    print(f\"-> 완료: ATT&CK 관련 피처 {attack_features_combined.shape[1]}개 생성.\\n\")\n",
    "else:\n",
    "    print(\"-> 완료: 처리할 ATT&CK 관련 컬럼이 없습니다.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cdc378-2e5b-4970-8c7e-2d5502865087",
   "metadata": {},
   "source": [
    "### ResponseInfo_detect_terminateprocess column\n",
    "[proc_relation_type] <br>\n",
    "부모/자식 정보가 모두 있으면 'ParentChild'<br>\n",
    "부모 없이 행위자만 있는 경우 'Self' <br>\n",
    "정보가 없으면 'None' <br>\n",
    "부모-자식 생성 관계인지, 아니면 단일 프로세스의 독립적인 악성 행위인지를 명확히 구분하여 모델에 알려줌 \n",
    "\n",
    "[parent_is_system, child_is_system] <br>\n",
    "시스템 프로세스 여부 <br>\n",
    "추출 방법: SystemService 필드(true/false)를 그대로 사용 <br>\n",
    "기대 효과: explorer.exe나 svchost.exe 같은 정상 시스템 프로세스가 악성 행위의 부모가 되는 경우가 많음. 이 플래그는 \"정상 프로세스를 이용한 공격\" 패턴을 학습하는 데 결정적인 역할을 함.<br>\n",
    "\n",
    "[is_parent_child_path_similar]<br>\n",
    "경로 유사성 <br>\n",
    "추출 방법: 부모의 ProcPath 디렉터리와 자식의 ProcPath 디렉터리가 동일한지 여부를 확인. (예: 둘 다 C:\\Users\\...\\AppData\\Local\\Temp에 위치)<br>\n",
    "기대 효과: 특정 폴더 내에서 파일 생성, 실행, 삭제가 연쇄적으로 일어나는 공격(예: Dropper)의 특징을 잡아낼 수 있음.<br>\n",
    "\n",
    "[parent_child_pair]<br>\n",
    "부모-자식 쌍(Pair) 피처화<br>\n",
    "추출 방법: ParentProcName과 ChildProcName을 -> 기호로 연결한 새로운 문자열 피처 많듦. (예: 'explorer.exe->malware.exe')<br>\n",
    "\n",
    "기대 효과: explorer.exe라는 단일 정보보다 'explorer.exe->malware.exe'라는 관계 정보가 훨씬 더 강력한 악성 지표가 되고 이 새로운 범주형 피처를 원-핫 인코딩하면 모델이 특정 생성 패턴을 직접적으로 학습 가능<br>\n",
    "\n",
    "[이벤트 프로세스와의 관계 정의]\n",
    "핵심: ResponseInfo의 정보와 이벤트 최상위 레벨의 ProcName을 비교.\n",
    "\n",
    "추출 방법:\n",
    "\n",
    "ResponseInfo의 자식 프로세스 이름이 최상위 ProcName과 같다면, 이 이벤트는 '생성된(Spawned)' 이벤트.\n",
    "\n",
    "ResponseInfo에 부모 프로세스만 있고, 그 이름이 최상위 ProcName과 같다면, 이 이벤트는 '생성하는(Spawning)' 이벤트.\n",
    "\n",
    "기대 효과: 이벤트의 역할을 명확하게 정의하여 시간의 흐름에 따른 인과관계를 모델이 더 잘 이해하도록 도움.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "'기원' vs '수행' == '부모' vs '자식/행위자'\n",
    "- 의심 행위를 수행한 프로세스 -> 자식/행위자 역할\n",
    "- 커맨드/스크립트를 실행한 프로세스의 부모 프로세스 -> 부모\n",
    "- 부모 프로세스 -> 부모\n",
    "- 자식 프로세스 -> 자식/행위자 역할\n",
    "- 커맨드/스크립트를 실행한 프로세스 -> 자식/행위자 역할\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c5ba5434-e4b8-45b3-9957-3049ae2d1aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "10a3ad53-63aa-4d7d-9fed-f8e3022f13e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 6. ResponseInfo_detect_terminateprocess 정보 피처 처리 시작 ###\n",
      "-> 완료: 프로세스 관계 피처 30개 생성.\n",
      "-> 완료: 부모/자식 CmdLine 피처 59개 생성.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"### 6. ResponseInfo_detect_terminateprocess 정보 피처 처리 시작 ###\")\n",
    "\n",
    "# ResponseInfo_detect_terminateprocess 필드에서 키워드 기반으로 피처 추\n",
    "def extract_advanced_process_info(row):\n",
    "\n",
    "    # 기본값 설정\n",
    "    parent_info = {'ProcName': 'Unknown', 'SystemService': False, 'ProcPath': '', 'CmdLine': ''}\n",
    "    child_info = {'ProcName': 'Unknown', 'SystemService': False, 'ProcPath': '', 'CmdLine': ''}\n",
    "\n",
    "    # 정보 추출\n",
    "    if isinstance(row['ResponseInfo_detect_terminateprocess'], list):\n",
    "        for item in row['ResponseInfo_detect_terminateprocess']:\n",
    "            desc = item.get('Description', '')\n",
    "\n",
    "            if '부모' in desc: # '부모' 키워드가 포함되어 있다면 parent_info로 간주\n",
    "                parent_info = item\n",
    "            elif any(keyword in desc for keyword in ['자식', '의심 행위', '커맨드/스크립트']): # 관련 키워드가 있으면 child_info로 간주\n",
    "                child_info = item\n",
    "    # 1. 관계 유형 피처\n",
    "    if parent_info['ProcName'] != 'Unknown' and child_info['ProcName'] != 'Unknown':\n",
    "        relation_type = 'ParentChild'\n",
    "    elif child_info['ProcName'] != 'Unknown':\n",
    "        relation_type = 'Self' # 부모 없이 행위자만 있는 경우\n",
    "    else:\n",
    "        relation_type = 'None'\n",
    "\n",
    "    # 2. 시스템 프로세스 여부\n",
    "    parent_is_system = parent_info.get('SystemService', False)\n",
    "    child_is_system = child_info.get('SystemService', False)\n",
    "\n",
    "    # 3. 경로 유사성\n",
    "    try:\n",
    "        parent_dir = '\\\\'.join(parent_info.get('ProcPath', '').split('\\\\')[:-1])\n",
    "        child_dir = '\\\\'.join(child_info.get('ProcPath', '').split('\\\\')[:-1])\n",
    "        is_path_similar = (parent_dir == child_dir) and parent_dir != ''\n",
    "    except:\n",
    "        is_path_similar = False\n",
    "\n",
    "    # 4. 부모-자식 쌍\n",
    "    parent_child_pair = f\"{parent_info.get('ProcName', 'Unknown')}->{child_info.get('ProcName', 'Unknown')}\"\n",
    "\n",
    "    return pd.Series([\n",
    "        relation_type,\n",
    "        parent_is_system,\n",
    "        child_is_system,\n",
    "        is_path_similar,\n",
    "        parent_child_pair,\n",
    "        parent_info.get('CmdLine', ''), \n",
    "        child_info.get('CmdLine', '')\n",
    "    ])\n",
    "\n",
    "if 'ResponseInfo_detect_terminateprocess' in feature_df.columns:\n",
    "    # 데이터프레임의 각 행에 함수 적용\n",
    "    new_proc_features = df.apply(extract_advanced_process_info, axis=1)\n",
    "    new_proc_features.columns = [\n",
    "        'proc_relation_type', 'parent_is_system', 'child_is_system',\n",
    "        'is_path_similar', 'parent_child_pair', 'parent_cmdline', 'child_cmdline'\n",
    "    ]\n",
    "\n",
    "    # 범주형/불리언 피처는 원-핫 인코딩 또는 그대로 사용\n",
    "    proc_categorical_features = pd.get_dummies(new_proc_features[[\n",
    "        'proc_relation_type', 'parent_is_system', 'child_is_system', \n",
    "        'is_path_similar', 'parent_child_pair'\n",
    "    ]])\n",
    "    feature_list.append(proc_categorical_features)\n",
    "    print(f\"-> 완료: 프로세스 관계 피처 {proc_categorical_features.shape[1]}개 생성.\")\n",
    "\n",
    "    # 부모/자식 CmdLine은 TF-IDF로 벡터화\n",
    "    # tfidf_parent_cmd = TfidfVectorizer(max_features=30, prefix='pcmd_')\n",
    "    tfidf_parent_cmd = TfidfVectorizer(max_features=30)\n",
    "    parent_cmd_vectors = tfidf_parent_cmd.fit_transform(new_proc_features['parent_cmdline'].fillna(''))\n",
    "    \n",
    "    parent_cmd_df = pd.DataFrame(\n",
    "        parent_cmd_vectors.toarray(),\n",
    "        columns=[f\"pcmd_{col}\" for col in tfidf_parent_cmd.get_feature_names_out()]  # ← 접두어 직접 추가\n",
    "    )\n",
    "    feature_list.append(parent_cmd_df)\n",
    "\n",
    "    # 자식 CmdLine TF-IDF\n",
    "    # tfidf_child_cmd = TfidfVectorizer(max_features=30, prefix='ccmd_')\n",
    "    tfidf_child_cmd = TfidfVectorizer(max_features=30)\n",
    "    child_cmd_vectors = tfidf_child_cmd.fit_transform(new_proc_features['child_cmdline'].fillna(''))\n",
    "    \n",
    "    # child_cmd_df = pd.DataFrame(child_cmd_vectors.toarray(), columns=tfidf_child_cmd.get_feature_names_out())\n",
    "        \n",
    "    child_cmd_df = pd.DataFrame(\n",
    "        child_cmd_vectors.toarray(),\n",
    "        columns=[f\"ccmd_{col}\" for col in tfidf_child_cmd.get_feature_names_out()]  # ← 접두어 직접 추가\n",
    "    )\n",
    "    feature_list.append(child_cmd_df)\n",
    "\n",
    "    print(f\"-> 완료: 부모/자식 CmdLine 피처 {parent_cmd_df.shape[1] + child_cmd_df.shape[1]}개 생성.\\n\")\n",
    "else:\n",
    "    print(\"-> 경고: 'ResponseInfo_detect_terminateprocess' 컬럼이 없습니다.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b83e69e-8fa2-4ae6-913d-35f19c6436f4",
   "metadata": {},
   "source": [
    "### 최종 모든 feature dataframe 병합 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8e90ba75-e0f4-4a57-a408-fa3959098ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 7. 최종 피처 병합 ###\n",
      "-> 완료: 모든 개별 피처 DataFrames 병합. (총 317개 피처)\n",
      "-> 완료: 최종 모델 입력 데이터프레임 생성. (shape: (58, 322))\n",
      "\n",
      "최종 데이터프레임 샘플 (상위 5개):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HostName</th>\n",
       "      <th>EventTime</th>\n",
       "      <th>threat_label_case_id</th>\n",
       "      <th>threat_label_verdict</th>\n",
       "      <th>threat_label_scenario</th>\n",
       "      <th>time_diff_sec</th>\n",
       "      <th>EventType_file</th>\n",
       "      <th>EventType_network</th>\n",
       "      <th>EventType_process</th>\n",
       "      <th>EventType_registry</th>\n",
       "      <th>...</th>\n",
       "      <th>ccmd_start</th>\n",
       "      <th>ccmd_system</th>\n",
       "      <th>ccmd_system32</th>\n",
       "      <th>ccmd_t1036</th>\n",
       "      <th>ccmd_temp</th>\n",
       "      <th>ccmd_txt</th>\n",
       "      <th>ccmd_username</th>\n",
       "      <th>ccmd_users</th>\n",
       "      <th>ccmd_vbs</th>\n",
       "      <th>ccmd_windows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DESKTOP-PJUQHNC</td>\n",
       "      <td>1759308290516</td>\n",
       "      <td>INCIDENT-20251001-003</td>\n",
       "      <td>malicious</td>\n",
       "      <td>Indicator Removal - Stop terminal from logging...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.579132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DESKTOP-PJUQHNC</td>\n",
       "      <td>1759308339416</td>\n",
       "      <td>INCIDENT-20251001-005</td>\n",
       "      <td>malicious</td>\n",
       "      <td>Indicator Removal - Prevent PowerShell history...</td>\n",
       "      <td>48.900</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516622</td>\n",
       "      <td>0.187143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DESKTOP-PJUQHNC</td>\n",
       "      <td>1759308455712</td>\n",
       "      <td>INCIDENT-20251001-004</td>\n",
       "      <td>malicious</td>\n",
       "      <td>Impair Defenses - Disable or Modify Security T...</td>\n",
       "      <td>116.296</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DESKTOP-PJUQHNC</td>\n",
       "      <td>1759308765584</td>\n",
       "      <td>INCIDENT-20251001-001</td>\n",
       "      <td>malicious</td>\n",
       "      <td>Ransomware</td>\n",
       "      <td>309.872</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516622</td>\n",
       "      <td>0.187143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DESKTOP-PJUQHNC</td>\n",
       "      <td>1759311540828</td>\n",
       "      <td>INCIDENT-20251001-008</td>\n",
       "      <td>malicious</td>\n",
       "      <td>Hide Artifacts - Create Hidden File with Attrib</td>\n",
       "      <td>2775.244</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 322 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          HostName      EventTime   threat_label_case_id threat_label_verdict  \\\n",
       "0  DESKTOP-PJUQHNC  1759308290516  INCIDENT-20251001-003            malicious   \n",
       "1  DESKTOP-PJUQHNC  1759308339416  INCIDENT-20251001-005            malicious   \n",
       "2  DESKTOP-PJUQHNC  1759308455712  INCIDENT-20251001-004            malicious   \n",
       "3  DESKTOP-PJUQHNC  1759308765584  INCIDENT-20251001-001            malicious   \n",
       "4  DESKTOP-PJUQHNC  1759311540828  INCIDENT-20251001-008            malicious   \n",
       "\n",
       "                               threat_label_scenario  time_diff_sec  \\\n",
       "0  Indicator Removal - Stop terminal from logging...          0.000   \n",
       "1  Indicator Removal - Prevent PowerShell history...         48.900   \n",
       "2  Impair Defenses - Disable or Modify Security T...        116.296   \n",
       "3                                         Ransomware        309.872   \n",
       "4    Hide Artifacts - Create Hidden File with Attrib       2775.244   \n",
       "\n",
       "   EventType_file  EventType_network  EventType_process  EventType_registry  \\\n",
       "0            True              False              False               False   \n",
       "1            True              False              False               False   \n",
       "2            True              False              False               False   \n",
       "3           False              False               True               False   \n",
       "4           False              False               True               False   \n",
       "\n",
       "   ...  ccmd_start  ccmd_system  ccmd_system32  ccmd_t1036  ccmd_temp  \\\n",
       "0  ...         0.0     0.000000       0.000000         0.0        0.0   \n",
       "1  ...         0.0     0.516622       0.187143         0.0        0.0   \n",
       "2  ...         0.0     0.000000       0.000000         0.0        0.0   \n",
       "3  ...         0.0     0.516622       0.187143         0.0        0.0   \n",
       "4  ...         0.0     0.000000       0.000000         0.0        0.0   \n",
       "\n",
       "   ccmd_txt  ccmd_username  ccmd_users  ccmd_vbs  ccmd_windows  \n",
       "0       0.0            0.0    0.579132       0.0      0.000000  \n",
       "1       0.0            0.0    0.000000       0.0      0.187143  \n",
       "2       0.0            0.0    0.492256       0.0      0.000000  \n",
       "3       0.0            0.0    0.000000       0.0      0.187143  \n",
       "4       0.0            0.0    0.000000       0.0      0.000000  \n",
       "\n",
       "[5 rows x 322 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 모든 피처 엔지니어링 완료! 'final_model_input.csv' 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"### 7. 최종 피처 병합 ###\")\n",
    "\n",
    "# feature_list에 저장된 모든 피처 데이터프레임을 수평으로(axis=1) 합칩니다.\n",
    "# 모든 피처가 feature_df와 동일한 인덱스(0, 1, 2...)를 기준으로 정렬되어 있습니다.\n",
    "try:\n",
    "    final_features_df = pd.concat(feature_list, axis=1)\n",
    "    print(f\"-> 완료: 모든 개별 피처 DataFrames 병합. (총 {final_features_df.shape[1]}개 피처)\")\n",
    "\n",
    "    # 모델 학습에 필요한 식별자, 레이블과 피처를 최종적으로 결합합니다.\n",
    "    # (중요) 1단계에서 정렬/인덱스 리셋을 마친 feature_df에서 컬럼을 가져옵니다.\n",
    "    key_columns = ['HostName', 'EventTime', 'threat_label_case_id', 'threat_label_verdict', 'threat_label_scenario']\n",
    "    \n",
    "    # feature_df에 실제 존재하는 키 컬럼만 선택합니다.\n",
    "    existing_key_columns = [col for col in key_columns if col in feature_df.columns]\n",
    "    \n",
    "    # 정렬된 키 컬럼 + 피처 컬럼을 수평으로 결합\n",
    "    final_model_input_df = pd.concat([\n",
    "        feature_df[existing_key_columns].reset_index(drop=True), # 안전을 위해 인덱스 리셋\n",
    "        final_features_df.reset_index(drop=True)\n",
    "    ], axis=1)\n",
    "\n",
    "    print(f\"-> 완료: 최종 모델 입력 데이터프레임 생성. (shape: {final_model_input_df.shape})\")\n",
    "    print(\"\\n최종 데이터프레임 샘플 (상위 5개):\")\n",
    "    display(final_model_input_df.head())\n",
    "    \n",
    "    # 다음 단계(모델 학습)를 위해 파일로 저장\n",
    "    output_filename = \"final_model_input.csv\"\n",
    "    final_model_input_df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\n✅ 모든 피처 엔지니어링 완료! '{output_filename}' 파일로 저장되었습니다.\")\n",
    "\n",
    "except ValueError as e:\n",
    "    print(f\"\\n[오류] 피처 병합 중 문제가 발생했습니다: {e}\")\n",
    "    print(\"feature_list에 있는 DataFrame들의 행(row) 개수가 일치하는지 확인해주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf573cb-942d-47e0-8237-c7a0c4917cad",
   "metadata": {},
   "source": [
    "## MLP 기반 샴 네트워크"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10569f80-7fa8-4c68-8e5b-44e3d8e39d42",
   "metadata": {},
   "source": [
    "### traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5903e3fc-2e0a-4f23-bf70-8f259f73f41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab235192-7423-4972-a3bc-e4b104757f30",
   "metadata": {},
   "source": [
    "#### 1. hyper parameterst 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "29c07617-80c3-4774-9cdb-11b2de341572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 1. 하이퍼파라미터 설정 --\n",
    "INPUT_FILE = \"final_model_input.csv\"\n",
    "MODEL_OUTPUT_DIR = \"model_checkpoint\" # 모델 저장용 디렉터리\n",
    "BEST_MODEL_NAME = \"best_mlp_base_network.pth\"\n",
    "\n",
    "# 데이터 분리 비율\n",
    "VAL_SPLIT_RATIO = 0.15\n",
    "TEST_SPLIT_RATIO = 0.15\n",
    "\n",
    "# 모델 파라미터\n",
    "EMBEDDING_SIZE = 64  # 이벤트 벡터를 압축할 최종 차원 (64차원 '지문')\n",
    "MARGIN = 2.0         # Contrastive Loss의 마진 값\n",
    "\n",
    "# 훈련 파라미터\n",
    "EPOCHS = 30          # 전체 데이터셋 반복 훈련 횟수\n",
    "BATCH_SIZE = 32      # 한 번에 훈련시킬 페어(pair)의 개수\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fd7890-977a-4f97-8e56-6cc662bf4834",
   "metadata": {},
   "source": [
    "#### 2. Pytorch 데이터셋 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "20421670-0625-4783-a8e5-64c785a2ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventPairDataset(Dataset):\n",
    "    \"\"\"\n",
    "    DataFrame을 직접 입력받아\n",
    "    (이벤트 A, 이벤트 B, 레이블) 페어를 생성하는 클래스\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe):\n",
    "        # 1. 키 컬럼과 피처 컬럼 분리\n",
    "        key_columns = ['HostName', 'EventTime', 'threat_label_case_id', 'threat_label_verdict', 'threat_label_scenario']\n",
    "        existing_key_columns = [col for col in dataframe.columns if col in key_columns]\n",
    "        feature_cols = [col for col in dataframe.columns if col not in existing_key_columns]\n",
    "        \n",
    "        # 2. 피처 데이터와 레이블(case_id) 저장\n",
    "        self.features = dataframe[feature_cols].values.astype(np.float32)\n",
    "        self.labels = dataframe['threat_label_case_id'].values\n",
    "        \n",
    "        # 3. Positive Pair를 빠르게 찾기 위한 맵(dict) 생성\n",
    "        self.label_to_indices = defaultdict(list)\n",
    "        for idx, label in enumerate(self.labels):\n",
    "            self.label_to_indices[label].append(idx)\n",
    "            \n",
    "        self.unique_labels = list(self.label_to_indices.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        anchor_event = self.features[index]\n",
    "        anchor_label = self.labels[index]\n",
    "        \n",
    "        if random.random() > 0.5:\n",
    "            # Positive 페어 (Label = 1.0)\n",
    "            positive_list = self.label_to_indices[anchor_label]\n",
    "            if len(positive_list) == 1:\n",
    "                positive_index = index\n",
    "            else:\n",
    "                # 자기 자신을 제외하고 랜덤 선택 (만약 자기 자신만 남으면 그냥 자기 자신)\n",
    "                positive_index = random.choice([i for i in positive_list if i != index] or [index])\n",
    "                \n",
    "            pair_event = self.features[positive_index]\n",
    "            label = 1.0\n",
    "        else:\n",
    "            # Negative 페어 (Label = 0.0)\n",
    "            # 다른 case_id에서 랜덤하게 이벤트 선택\n",
    "            negative_label = random.choice([l for l in self.unique_labels if l != anchor_label])\n",
    "            negative_index = random.choice(self.label_to_indices[negative_label])\n",
    "            \n",
    "            pair_event = self.features[negative_index]\n",
    "            label = 0.0\n",
    "            \n",
    "        return (\n",
    "            torch.tensor(anchor_event, dtype=torch.float32),\n",
    "            torch.tensor(pair_event, dtype=torch.float32),\n",
    "            torch.tensor([label], dtype=torch.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00036f9-33d0-4771-8db3-abc049e78c61",
   "metadata": {},
   "source": [
    "#### 3. AI 모델 및 손실 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cb7a1c0e-d3a3-4390-9cbc-c05ca692a107",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpBaseNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    이벤트 벡터(1D)를 입력받아 임베딩 벡터(1D)를 출력하는 Base Network\n",
    "    (LSTM이 아닌 MLP/FFN 구조)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, embedding_size):\n",
    "        super(MlpBaseNetwork, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256), # 과적합 방지 및 안정화\n",
    "            nn.Dropout(0.3),     # 과적합 방지\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, embedding_size) # 최종 '지문' 벡터\n",
    "        )\n",
    "    \n",
    "    def forward(self, x_event):\n",
    "        # x_event shape: (batch_size, input_size)\n",
    "        embedding = self.network(x_event)\n",
    "        return embedding\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    두 개의 이벤트를 입력받는 샴 네트워크\n",
    "    \"\"\"\n",
    "    def __init__(self, base_network):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.base_network = base_network\n",
    "\n",
    "    def forward(self, event1, event2):\n",
    "        embedding1 = self.base_network(event1)\n",
    "        embedding2 = self.base_network(event2)\n",
    "        return embedding1, embedding2\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    대조 손실 함수\n",
    "    Label=1 이면 거리를 가깝게, Label=0 이면 거리를 margin보다 멀게 학습\n",
    "    \"\"\"\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.eps = 1e-9 # 0으로 나누는 것을 방지\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        # 유클리드 거리 계산\n",
    "        euclidean_distance = nn.functional.pairwise_distance(output1, output2) + self.eps\n",
    "        \n",
    "        # Contrastive Loss 계산\n",
    "        loss_contrastive = torch.mean(\n",
    "            (label) * torch.pow(euclidean_distance, 2) +\n",
    "            (1 - label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        )\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcfa75b-d73e-47f3-8869-d31cfc057029",
   "metadata": {},
   "source": [
    "#### 4. 검증(Validation) 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ed7335bc-31bc-4426-9b8e-ccf53c7a0de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, criterion, device):\n",
    "    \"\"\"\n",
    "    검증 데이터셋으로 모델의 손실(loss)을 평가하는 함수\n",
    "    \"\"\"\n",
    "    model.eval() # 평가 모드 (Dropout, BatchNorm 비활성화)\n",
    "    total_loss = 0\n",
    "    with torch.no_grad(): # 기울기 계산 비활성화 (메모리 절약, 속도 향상)\n",
    "        for anchor_event, pair_event, label in loader:\n",
    "            anchor_event = anchor_event.to(device)\n",
    "            pair_event = pair_event.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            output1, output2 = model(anchor_event, pair_event)\n",
    "            loss = criterion(output1, output2, label)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6fd7d8-a1db-4e75-860d-57f1c67777c8",
   "metadata": {},
   "source": [
    "#### 피처 엔지니어링 도구 저장 \n",
    "-> 학습 데이터 기준으로 fit된 모든 전처리기의 최종 컬럼 목록을 preprocessors.joblib 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1c24cebf-ac82-4604-a803-9e852cc4717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "87661fb7-e86b-469c-80a8-43ed05b88b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 8. (신규) 추론을 위한 피처 엔지니어링 도구 저장 ###\n",
      "✅ 전처리기 도구 저장 완료: model_checkpoint/preprocessors.joblib\n",
      "저장된 항목: ['fields_to_include', 'cmdline_tfidf', 'path_word_to_idx', 'path_embedder_params', 'attack_mlbs', 'parent_cmd_tfidf', 'child_cmd_tfidf', 'final_feature_columns']\n"
     ]
    }
   ],
   "source": [
    "print(\"### 8. (신규) 추론을 위한 피처 엔지니어링 도구 저장 ###\")\n",
    "\n",
    "# 1. 저장할 디렉터리 생성 (모델 저장 위치와 동일하게 사용)\n",
    "MODEL_OUTPUT_DIR = \"model_checkpoint\" \n",
    "os.makedirs(MODEL_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 2. 전처리기 도구들을 딕셔너리에 수집\n",
    "# (주의: 변수명은 Sagemaker 노트북의 각 셀에서 사용된 최종 변수명과 일치해야 합니다)\n",
    "preprocessors = {}\n",
    "\n",
    "try:\n",
    "    # --- ES 조회 필드 목록 저장 ---\n",
    "    if 'fields_to_include' in locals():\n",
    "        preprocessors['fields_to_include'] = fields_to_include\n",
    "    else:\n",
    "        print(\"경고: 'fields_to_include' 변수를 찾을 수 없습니다.\")\n",
    "\n",
    "    # --- 3. 텍스트 피처 (CmdLine) ---\n",
    "    if 'tfidf_vectorizer' in locals():\n",
    "        preprocessors['cmdline_tfidf'] = tfidf_vectorizer\n",
    "\n",
    "    # --- 4. 경로 피처 (ProcPath) ---\n",
    "    if 'word_to_idx' in locals():\n",
    "        preprocessors['path_word_to_idx'] = word_to_idx\n",
    "        preprocessors['path_embedder_params'] = {\n",
    "            'vocab_size': vocab_size,\n",
    "            'embedding_dim': EMBEDDING_DIM,\n",
    "            'hidden_dim': HIDDEN_DIM\n",
    "        }\n",
    "\n",
    "    # --- 5. ATT&CK 피처 (TacticID, TechniqueID) ---\n",
    "    if 'attack_mlbs' in locals():\n",
    "         preprocessors['attack_mlbs'] = attack_mlbs\n",
    "\n",
    "    # --- 6. ResponseInfo 피처 ---\n",
    "    if 'tfidf_parent_cmd' in locals():\n",
    "        preprocessors['parent_cmd_tfidf'] = tfidf_parent_cmd\n",
    "    if 'tfidf_child_cmd' in locals():\n",
    "        preprocessors['child_cmd_tfidf'] = tfidf_child_cmd\n",
    "    \n",
    "    # --- 7. 최종 컬럼 목록 ---\n",
    "    if 'final_features_df' in locals():\n",
    "        preprocessors['final_feature_columns'] = final_features_df.columns.tolist()\n",
    "    else:\n",
    "        raise ValueError(\"final_features_df가 정의되지 않았습니다. 7단계가 정상 실행되었는지 확인하세요.\")\n",
    "\n",
    "    # 3. 파일로 저장\n",
    "    preprocessor_path = os.path.join(MODEL_OUTPUT_DIR, \"preprocessors.joblib\")\n",
    "    joblib.dump(preprocessors, preprocessor_path)\n",
    "    \n",
    "    print(f\"✅ 전처리기 도구 저장 완료: {preprocessor_path}\")\n",
    "    print(f\"저장된 항목: {list(preprocessors.keys())}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[오류] 전처리기 저장 중 문제 발생: {e}\")\n",
    "    print(\"-> 각 단계(3, 4, 5, 6, 7)의 변수명(tfidf_vectorizer, word_to_idx 등)이 올바른지 확인하세요.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ac81be-ef22-4e1c-be28-a31ae18d1b5f",
   "metadata": {},
   "source": [
    "#### 5. 훈련(Training) 스크립트 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9ddf9b2b-ba4a-4965-85e8-06588a195bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'final_model_input.csv' 파일 로드 및 그룹 기반 분리 시작...\n",
      "데이터 분리 완료:\n",
      "  - Train Set: 26개 Case ID, 36개 이벤트\n",
      "  - Val Set  : 5개 Case ID, 12개 이벤트\n",
      "  - Test Set : 5개 Case ID, 10개 이벤트\n",
      "\n",
      "훈련 시작... Device: cpu\n",
      "입력 피처 수: 317, 임베딩 크기: 64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 85.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 완료 | Train Loss: 22.0550 | Val Loss: 705.1249\n",
      "  -> Validation Loss 개선! 베스트 모델 저장: model_checkpoint/best_mlp_base_network.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 121.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 완료 | Train Loss: 38.1176 | Val Loss: 533.5474\n",
      "  -> Validation Loss 개선! 베스트 모델 저장: model_checkpoint/best_mlp_base_network.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 125.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 완료 | Train Loss: 18.8339 | Val Loss: 421.4908\n",
      "  -> Validation Loss 개선! 베스트 모델 저장: model_checkpoint/best_mlp_base_network.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 92.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 완료 | Train Loss: 16.4985 | Val Loss: 607.2806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 116.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 완료 | Train Loss: 10.7949 | Val Loss: 963.4202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 127.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 완료 | Train Loss: 12.5174 | Val Loss: 187.4905\n",
      "  -> Validation Loss 개선! 베스트 모델 저장: model_checkpoint/best_mlp_base_network.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 132.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 완료 | Train Loss: 7.1945 | Val Loss: 95.0134\n",
      "  -> Validation Loss 개선! 베스트 모델 저장: model_checkpoint/best_mlp_base_network.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 118.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 완료 | Train Loss: 8.3254 | Val Loss: 97.9440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 84.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 완료 | Train Loss: 16.3744 | Val Loss: 602.9628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 125.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 완료 | Train Loss: 13.3937 | Val Loss: 671.3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 138.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 완료 | Train Loss: 23.1016 | Val Loss: 455.0936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 132.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 완료 | Train Loss: 15.2436 | Val Loss: 264.0363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 135.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 완료 | Train Loss: 18.7163 | Val Loss: 50.0028\n",
      "  -> Validation Loss 개선! 베스트 모델 저장: model_checkpoint/best_mlp_base_network.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 130.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 완료 | Train Loss: 14.1319 | Val Loss: 199.1831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 134.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 완료 | Train Loss: 5.3548 | Val Loss: 53.1447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 131.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 완료 | Train Loss: 8.7092 | Val Loss: 65.5678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 146.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 완료 | Train Loss: 19.0753 | Val Loss: 186.6539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 135.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 완료 | Train Loss: 11.9317 | Val Loss: 52.0544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 136.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 완료 | Train Loss: 11.2791 | Val Loss: 243.9752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 147.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 완료 | Train Loss: 15.8209 | Val Loss: 80.8892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 96.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 완료 | Train Loss: 11.2954 | Val Loss: 244.0966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 122.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 완료 | Train Loss: 18.8246 | Val Loss: 93.9698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 101.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 완료 | Train Loss: 16.5990 | Val Loss: 182.0208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 106.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 완료 | Train Loss: 8.8108 | Val Loss: 49.8012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Validation Loss 개선! 베스트 모델 저장: model_checkpoint/best_mlp_base_network.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 122.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 완료 | Train Loss: 9.0995 | Val Loss: 191.3871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 130.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 완료 | Train Loss: 9.8367 | Val Loss: 112.4034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 125.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 완료 | Train Loss: 7.3790 | Val Loss: 67.7571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 133.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 완료 | Train Loss: 6.9792 | Val Loss: 101.8444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 144.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 완료 | Train Loss: 11.0977 | Val Loss: 124.9004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30 [Train]: 100%|██████████| 2/2 [00:00<00:00, 128.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30 완료 | Train Loss: 12.7569 | Val Loss: 57.2597\n",
      "\n",
      "🎉 훈련이 완료되었습니다!\n",
      "가장 낮은 검증 손실(Best Val Loss): 49.8012\n",
      "\n",
      "최종 Test Set으로 성능을 평가합니다...\n",
      "\n",
      "✅ 최종 Test Loss: 3.6711\n",
      "이것이 모델의 일반화 성능입니다.\n",
      "\n",
      "--- [Test Set 그룹핑 결과 확인] ---\n",
      "Test Set 이벤트 10개에 대한 임베딩 추출 중...\n",
      "임베딩 추출 완료.\n",
      "\n",
      "--- [모델 그룹핑 결과 (임계값: 0.80)] ---\n",
      "    predicted_cluster_id   threat_label_case_id      EventTime                              threat_label_scenario\n",
      "1                      0  INCIDENT-20251001-005  1759308339416  Indicator Removal - Prevent PowerShell history...\n",
      "3                      0  INCIDENT-20251001-001  1759308765584                                         Ransomware\n",
      "7                      0  INCIDENT-20251001-005  1759387591524  Indicator Removal - Prevent PowerShell history...\n",
      "9                      0  INCIDENT-20251001-001  1759388257777                                         Ransomware\n",
      "10                     0  INCIDENT-20251001-002  1759388362872  Command and Scripting Interpreter - PowerShell...\n",
      "35                     0  INCIDENT-20251003-024  1759471547834                                         Ransomware\n",
      "37                     0  INCIDENT-20251003-024  1759471600787                                         Ransomware\n",
      "47                     0   INCIDENT-20251010-38  1760082754633             Execution - Remote Access/Support Tool\n",
      "38                     1  INCIDENT-20251003-024  1759471601287                                         Ransomware\n",
      "39                     2  INCIDENT-20251003-024  1759471608990                                         Ransomware\n",
      "\n",
      "[결과 해석 가이드]\n",
      " - 'predicted_cluster_id'가 모델이 예측한 그룹입니다.\n",
      " - 'threat_label_case_id'가 실제 정답 그룹입니다.\n",
      " - **정답과 예측이 일치하는지** (예: predicted_cluster_id '3'에 case_id 'INCIDENT-XXX-010'만 있는지) 확인해보세요.\n",
      " - 만약 그룹이 너무 잘게 쪼개진다면 -> 'clustering_threshold' 값을 더 높여보세요 (예: 1.5 -> 1.8).\n",
      " - 만약 그룹이 너무 크게 하나로 묶인다면 -> 'clustering_threshold' 값을 더 낮춰보세요 (예: 1.5 -> 1.2).\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # -- [핵심] 그룹(case_id) 기반 데이터 분리 --\n",
    "    print(f\"'{INPUT_FILE}' 파일 로드 및 그룹 기반 분리 시작...\")\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "    \n",
    "    # 1. 고유한 case_id 리스트 추출\n",
    "    unique_case_ids = df['threat_label_case_id'].unique()\n",
    "    np.random.shuffle(unique_case_ids) # case_id 리스트를 섞음\n",
    "    \n",
    "    # 2. Test, Validation, Train 용 case_id 분리\n",
    "    test_size = int(len(unique_case_ids) * TEST_SPLIT_RATIO)\n",
    "    val_size = int(len(unique_case_ids) * VAL_SPLIT_RATIO)\n",
    "    \n",
    "    test_ids = unique_case_ids[:test_size]\n",
    "    val_ids = unique_case_ids[test_size : test_size + val_size]\n",
    "    train_ids = unique_case_ids[test_size + val_size:]\n",
    "    \n",
    "    # 3. case_id 리스트를 기준으로 DataFrame 분리\n",
    "    train_df = df[df['threat_label_case_id'].isin(train_ids)]\n",
    "    val_df = df[df['threat_label_case_id'].isin(val_ids)]\n",
    "    test_df = df[df['threat_label_case_id'].isin(test_ids)]\n",
    "    \n",
    "    print(\"데이터 분리 완료:\")\n",
    "    print(f\"  - Train Set: {len(train_ids)}개 Case ID, {len(train_df)}개 이벤트\")\n",
    "    print(f\"  - Val Set  : {len(val_ids)}개 Case ID, {len(val_df)}개 이벤트\")\n",
    "    print(f\"  - Test Set : {len(test_ids)}개 Case ID, {len(test_df)}개 이벤트\")\n",
    "    \n",
    "    # 4. 데이터셋 및 데이터로더 준비\n",
    "    train_dataset = EventPairDataset(dataframe=train_df)\n",
    "    val_dataset = EventPairDataset(dataframe=val_df)\n",
    "    # Test 데이터셋은 나중에 최종 평가 시 사용\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    # 5. 모델, 손실함수, 옵티마이저 초기화\n",
    "    INPUT_SIZE = train_dataset.features.shape[1] \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\n훈련 시작... Device: {device}\")\n",
    "    print(f\"입력 피처 수: {INPUT_SIZE}, 임베딩 크기: {EMBEDDING_SIZE}\\n\")\n",
    "\n",
    "    base_net = MlpBaseNetwork(INPUT_SIZE, EMBEDDING_SIZE).to(device)\n",
    "    model = SiameseNetwork(base_net).to(device)\n",
    "    criterion = ContrastiveLoss(margin=MARGIN).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # 모델 체크포인트 디렉터리 생성\n",
    "    os.makedirs(MODEL_OUTPUT_DIR, exist_ok=True)\n",
    "    best_model_path = os.path.join(MODEL_OUTPUT_DIR, BEST_MODEL_NAME)\n",
    "    \n",
    "    # 6. 훈련 루프 (검증 및 모델 저장 로직 추가)\n",
    "    best_val_loss = float('inf') # 가장 낮은 검증 손실을 추적\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train() # 훈련 모드\n",
    "        total_train_loss = 0\n",
    "        \n",
    "        for anchor_event, pair_event, label in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\"):\n",
    "            anchor_event, pair_event, label = anchor_event.to(device), pair_event.to(device), label.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output1, output2 = model(anchor_event, pair_event)\n",
    "            loss = criterion(output1, output2, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        # --- [검증 단계] ---\n",
    "        avg_val_loss = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} 완료 | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # --- [베스트 모델 저장] ---\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            # (중요) 샴 네트워크(model)가 아닌 Base Network(base_net)의 가중치를 저장\n",
    "            torch.save(base_net.state_dict(), best_model_path)\n",
    "            print(f\"  -> Validation Loss 개선! 베스트 모델 저장: {best_model_path}\")\n",
    "\n",
    "    print(\"\\n🎉 훈련이 완료되었습니다!\")\n",
    "    print(f\"가장 낮은 검증 손실(Best Val Loss): {best_val_loss:.4f}\")\n",
    "\n",
    "    # -- 7. 최종 Test Set 평가 (참고) --\n",
    "    print(\"\\n최종 Test Set으로 성능을 평가합니다...\")\n",
    "    # 저장된 베스트 모델 가중치를 로드\n",
    "    final_base_net = MlpBaseNetwork(INPUT_SIZE, EMBEDDING_SIZE).to(device)\n",
    "    final_base_net.load_state_dict(torch.load(best_model_path))\n",
    "    final_model = SiameseNetwork(final_base_net).to(device)\n",
    "\n",
    "    # Test 데이터로더 생성 및 평가\n",
    "    test_dataset = EventPairDataset(dataframe=test_df)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    final_test_loss = validate(final_model, test_loader, criterion, device)\n",
    "    print(f\"\\n✅ 최종 Test Loss: {final_test_loss:.4f}\")\n",
    "    print(\"이것이 모델의 일반화 성능입니다.\")\n",
    "\n",
    "    print(\"\\n--- [Test Set 그룹핑 결과 확인] ---\")\n",
    "\n",
    "    # 1. 필요한 라이브러리 임포트\n",
    "    from sklearn.cluster import AgglomerativeClustering\n",
    "    import pandas as pd\n",
    "    from IPython.display import display\n",
    "    \n",
    "    # 2. 'final_base_net' (베스트 모델)을 평가 모드로 설정\n",
    "    final_base_net.eval()\n",
    "    \n",
    "    # 3. Test DataFrame(test_df)에서 피처만 추출하여 텐서로 변환\n",
    "    # (훈련/검증/테스트 분리 시 사용했던 key_columns를 다시 정의)\n",
    "    key_columns = ['HostName', 'EventTime', 'threat_label_case_id', 'threat_label_verdict', 'threat_label_scenario']\n",
    "    existing_key_columns = [col for col in test_df.columns if col in key_columns]\n",
    "    feature_cols = [col for col in test_df.columns if col not in existing_key_columns]\n",
    "    \n",
    "    test_features_np = test_df[feature_cols].values.astype(np.float32)\n",
    "    test_features_tensor = torch.tensor(test_features_np).to(device)\n",
    "    \n",
    "    print(f\"Test Set 이벤트 {len(test_features_tensor)}개에 대한 임베딩 추출 중...\")\n",
    "    \n",
    "    # 4. 모든 Test Set 이벤트의 임베딩을 한 번에 계산\n",
    "    with torch.no_grad():\n",
    "        all_embeddings = final_base_net(test_features_tensor)\n",
    "        all_embeddings_np = all_embeddings.cpu().numpy()\n",
    "    \n",
    "    print(\"임베딩 추출 완료.\")\n",
    "\n",
    "    # 5. Scikit-learn을 사용한 클러스터링 (그룹핑)\n",
    "    # AgglomerativeClustering: 임베딩 벡터 간의 거리를 기반으로 그룹을 묶음\n",
    "    \n",
    "    # distance_threshold: 이 거리(임계값) 내에 있는 벡터들은 같은 클러스터로 묶임\n",
    "    # **[매우 중요]** 이 임계값은 모델의 학습 결과에 따라 사용자가 직접 조정해야 합니다.\n",
    "    # 보통 MARGIN(2.0) 값의 50% ~ 75% 사이에서 시작하는 것이 좋습니다.\n",
    "    # clustering_threshold = MARGIN * 0.75 # (예: 2.0 * 0.75 = 1.5)\n",
    "\n",
    "    clustering_threshold = 0.8\n",
    "    \n",
    "    clustering = AgglomerativeClustering(\n",
    "        n_clusters=None, # 클러스터 개수를 미리 정하지 않음\n",
    "        distance_threshold=clustering_threshold, # 거리 임계값 기준으로 묶음\n",
    "        metric='euclidean',\n",
    "        linkage='average' # 클러스터 간의 '평균' 거리를 사용\n",
    "    )\n",
    "    \n",
    "    predicted_labels = clustering.fit_predict(all_embeddings_np)\n",
    "\n",
    "    # 6. 원본 DataFrame에 예측된 그룹핑 결과(predicted_cluster_id)를 추가\n",
    "    results_df = test_df.copy()\n",
    "    results_df['predicted_cluster_id'] = predicted_labels # 모델이 예측한 그룹 ID\n",
    "    \n",
    "    # 7. 결과 출력\n",
    "    # 'predicted_cluster_id' (예측값)으로 먼저 정렬한 뒤, 'EventTime'으로 정렬\n",
    "    results_df_sorted = results_df.sort_values(by=['predicted_cluster_id', 'EventTime'])\n",
    "    \n",
    "    print(f\"\\n--- [모델 그룹핑 결과 (임계값: {clustering_threshold:.2f})] ---\")\n",
    "    \n",
    "    # 컬럼이 너무 많으면 보기 힘드므로, 핵심 컬럼만 선택\n",
    "    display_columns = ['predicted_cluster_id', 'threat_label_case_id', 'EventTime', 'threat_label_scenario']\n",
    "    available_display_columns = [col for col in display_columns if col in results_df.columns]\n",
    "    \n",
    "    # pandas가 모든 행을 출력하도록 설정\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', 1000):\n",
    "        print(results_df_sorted[available_display_columns])\n",
    "        \n",
    "    print(\"\\n[결과 해석 가이드]\")\n",
    "    print(\" - 'predicted_cluster_id'가 모델이 예측한 그룹입니다.\")\n",
    "    print(\" - 'threat_label_case_id'가 실제 정답 그룹입니다.\")\n",
    "    print(\" - **정답과 예측이 일치하는지** (예: predicted_cluster_id '3'에 case_id 'INCIDENT-XXX-010'만 있는지) 확인해보세요.\")\n",
    "    print(\" - 만약 그룹이 너무 잘게 쪼개진다면 -> 'clustering_threshold' 값을 더 높여보세요 (예: 1.5 -> 1.8).\")\n",
    "    print(\" - 만약 그룹이 너무 크게 하나로 묶인다면 -> 'clustering_threshold' 값을 더 낮춰보세요 (예: 1.5 -> 1.2).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "be13edea-5859-40ea-98b1-d722e832473b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- [Test Set 그룹핑 결과 확인] ---\n",
      "Test Set 이벤트 10개에 대한 임베딩 추출 중...\n",
      "임베딩 추출 완료.\n",
      "\n",
      "--- [모델 그룹핑 결과 (임계값: 1.50)] ---\n",
      "    predicted_cluster_id   threat_label_case_id      EventTime                              threat_label_scenario\n",
      "1                      0  INCIDENT-20251001-005  1759308339416  Indicator Removal - Prevent PowerShell history...\n",
      "3                      0  INCIDENT-20251001-001  1759308765584                                         Ransomware\n",
      "7                      0  INCIDENT-20251001-005  1759387591524  Indicator Removal - Prevent PowerShell history...\n",
      "9                      0  INCIDENT-20251001-001  1759388257777                                         Ransomware\n",
      "10                     0  INCIDENT-20251001-002  1759388362872  Command and Scripting Interpreter - PowerShell...\n",
      "35                     0  INCIDENT-20251003-024  1759471547834                                         Ransomware\n",
      "37                     0  INCIDENT-20251003-024  1759471600787                                         Ransomware\n",
      "39                     0  INCIDENT-20251003-024  1759471608990                                         Ransomware\n",
      "47                     0   INCIDENT-20251010-38  1760082754633             Execution - Remote Access/Support Tool\n",
      "38                     1  INCIDENT-20251003-024  1759471601287                                         Ransomware\n",
      "\n",
      "[결과 해석 가이드]\n",
      " - 'predicted_cluster_id'가 모델이 예측한 그룹입니다.\n",
      " - 'threat_label_case_id'가 실제 정답 그룹입니다.\n",
      " - **정답과 예측이 일치하는지** (예: predicted_cluster_id '3'에 case_id 'INCIDENT-XXX-010'만 있는지) 확인해보세요.\n",
      " - 만약 그룹이 너무 잘게 쪼개진다면 -> 'clustering_threshold' 값을 더 높여보세요 (예: 1.5 -> 1.8).\n",
      " - 만약 그룹이 너무 크게 하나로 묶인다면 -> 'clustering_threshold' 값을 더 낮춰보세요 (예: 1.5 -> 1.2).\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- [Test Set 그룹핑 결과 확인] ---\")\n",
    "\n",
    "# 1. 필요한 라이브러리 임포트\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# 2. 'final_base_net' (베스트 모델)을 평가 모드로 설정\n",
    "final_base_net.eval()\n",
    "\n",
    "# 3. Test DataFrame(test_df)에서 피처만 추출하여 텐서로 변환\n",
    "# (훈련/검증/테스트 분리 시 사용했던 key_columns를 다시 정의)\n",
    "key_columns = ['HostName', 'EventTime', 'threat_label_case_id', 'threat_label_verdict', 'threat_label_scenario']\n",
    "existing_key_columns = [col for col in test_df.columns if col in key_columns]\n",
    "feature_cols = [col for col in test_df.columns if col not in existing_key_columns]\n",
    "\n",
    "test_features_np = test_df[feature_cols].values.astype(np.float32)\n",
    "test_features_tensor = torch.tensor(test_features_np).to(device)\n",
    "\n",
    "print(f\"Test Set 이벤트 {len(test_features_tensor)}개에 대한 임베딩 추출 중...\")\n",
    "\n",
    "# 4. 모든 Test Set 이벤트의 임베딩을 한 번에 계산\n",
    "with torch.no_grad():\n",
    "    all_embeddings = final_base_net(test_features_tensor)\n",
    "    all_embeddings_np = all_embeddings.cpu().numpy()\n",
    "\n",
    "print(\"임베딩 추출 완료.\")\n",
    "\n",
    "# 5. Scikit-learn을 사용한 클러스터링 (그룹핑)\n",
    "# AgglomerativeClustering: 임베딩 벡터 간의 거리를 기반으로 그룹을 묶음\n",
    "\n",
    "# distance_threshold: 이 거리(임계값) 내에 있는 벡터들은 같은 클러스터로 묶임\n",
    "# **[매우 중요]** 이 임계값은 모델의 학습 결과에 따라 사용자가 직접 조정해야 합니다.\n",
    "# 보통 MARGIN(2.0) 값의 50% ~ 75% 사이에서 시작하는 것이 좋습니다.\n",
    "clustering_threshold = MARGIN * 0.75 # (예: 2.0 * 0.75 = 1.5)\n",
    "\n",
    "clustering = AgglomerativeClustering(\n",
    "    n_clusters=None, # 클러스터 개수를 미리 정하지 않음\n",
    "    distance_threshold=clustering_threshold, # 거리 임계값 기준으로 묶음\n",
    "    metric='euclidean',\n",
    "    linkage='average' # 클러스터 간의 '평균' 거리를 사용\n",
    ")\n",
    "\n",
    "predicted_labels = clustering.fit_predict(all_embeddings_np)\n",
    "\n",
    "# 6. 원본 DataFrame에 예측된 그룹핑 결과(predicted_cluster_id)를 추가\n",
    "results_df = test_df.copy()\n",
    "results_df['predicted_cluster_id'] = predicted_labels # 모델이 예측한 그룹 ID\n",
    "\n",
    "# 7. 결과 출력\n",
    "# 'predicted_cluster_id' (예측값)으로 먼저 정렬한 뒤, 'EventTime'으로 정렬\n",
    "results_df_sorted = results_df.sort_values(by=['predicted_cluster_id', 'EventTime'])\n",
    "\n",
    "print(f\"\\n--- [모델 그룹핑 결과 (임계값: {clustering_threshold:.2f})] ---\")\n",
    "\n",
    "# 컬럼이 너무 많으면 보기 힘드므로, 핵심 컬럼만 선택\n",
    "display_columns = ['predicted_cluster_id', 'threat_label_case_id', 'EventTime', 'threat_label_scenario']\n",
    "available_display_columns = [col for col in display_columns if col in results_df.columns]\n",
    "\n",
    "# pandas가 모든 행을 출력하도록 설정\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', 1000):\n",
    "    print(results_df_sorted[available_display_columns])\n",
    "    \n",
    "print(\"\\n[결과 해석 가이드]\")\n",
    "print(\" - 'predicted_cluster_id'가 모델이 예측한 그룹입니다.\")\n",
    "print(\" - 'threat_label_case_id'가 실제 정답 그룹입니다.\")\n",
    "print(\" - **정답과 예측이 일치하는지** (예: predicted_cluster_id '3'에 case_id 'INCIDENT-XXX-010'만 있는지) 확인해보세요.\")\n",
    "print(\" - 만약 그룹이 너무 잘게 쪼개진다면 -> 'clustering_threshold' 값을 더 높여보세요 (예: 1.5 -> 1.8).\")\n",
    "print(\" - 만약 그룹이 너무 크게 하나로 묶인다면 -> 'clustering_threshold' 값을 더 낮춰보세요 (예: 1.5 -> 1.2).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
